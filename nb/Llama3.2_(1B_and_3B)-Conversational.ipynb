{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mpb-YkBus-L"
      },
      "source": [
        "To run this, press \"*Runtime*\" and press \"*Run all*\" on a **free** Tesla T4 Google Colab instance!\n",
        "<div class=\"align-center\">\n",
        "<a href=\"https://unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "<a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord button.png\" width=\"145\"></a>\n",
        "<a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a></a> Join Discord if you need help + ‚≠ê <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠ê\n",
        "</div>\n",
        "\n",
        "To install Unsloth on your own computer, follow the installation instructions on our Github page [here](https://docs.unsloth.ai/get-started/installing-+-updating).\n",
        "\n",
        "You will learn how to do [data prep](#Data), how to [train](#Train), how to [run the model](#Inference), & [how to save it](#Save)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49vmDhoLus-M"
      },
      "source": [
        "### News"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0d5xRjFus-N"
      },
      "source": [
        "**Read our [Gemma 3 blog](https://unsloth.ai/blog/gemma3) for what's new in Unsloth and our [Reasoning blog](https://unsloth.ai/blog/r1-reasoning) on how to train reasoning models.**\n",
        "\n",
        "Visit our docs for all our [model uploads](https://docs.unsloth.ai/get-started/all-our-models) and [notebooks](https://docs.unsloth.ai/get-started/unsloth-notebooks).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhVk59a8us-N"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uRroaiqTus-N"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth\n",
        "\n",
        "    from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULGxYQUWus-N"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "c3bebecbd48d4522bab6611255a64f9f",
            "bf0c470d44cd45a5a1dd523b2b17d8f3",
            "9ffea1ec2a1e4f3fb6d93e7fca53606f",
            "af2944cd893d4acaa9bf8ada72d6c040",
            "49c962fd2fc2490ea07bdbd9850022d8",
            "81c0551ea8fa4a9c91130b436916d769",
            "147640b2354e4f0aa11c0b203e32dea5",
            "bb3b8e761fd1414db331bc12ffc704f6",
            "d8ca9ea138f340e6b738f440ac05e6da",
            "e1d254c3c25841f79d67903dfa039415",
            "ab6ffa70c77d402f84cf58be80b4a328",
            "a23b252875e242da8b7ecabaf8e08bc8",
            "13cfc66228c44bd68d6cc77ff4697a58",
            "5f604b90d395441e862616df04da2cd8",
            "7489fb2e9be248878b6195033b637e2c",
            "d0db9b51e9af45dc9b1da6a01dfb081a",
            "1fe8a317af924c388abda2e543bff090",
            "12cdc1f761dd481ab530275bd0744746",
            "b5f53a72eb6f4f4e90bfa9425c59c66c",
            "3958675895a747ea9b340e0ebf8a0a31",
            "79d4c701d3c544198d280a8f2acbf22a",
            "e4ff4b412d5b47a580b65a308f3e7952",
            "44c2a8346d0149f0ae67975557b65ced",
            "496e73a1e1794280bdfdd0ebea474744",
            "f3ddbffb0869478298fbc8de810a7cf8",
            "6443d11b2d5a4215b61c3478b3845741",
            "9d65638fc98f4f9fb683dad3ffe072e4",
            "6fa9aeb577c048ae822dc22718429941",
            "480767b02c3b4bc0bb155f01f7cc66a0",
            "384276b53c64497598411b6109a377d9",
            "61f576ebd82e4e0d832875e6230bfca9",
            "4659321d09624f838638199ee8ccd7eb",
            "3cd700d9a4c64b55bdf8a5c2bfbe02f1",
            "27975910e7ce4a85a6cefd49e33f9f6a",
            "cbcdaa17ac524be087d174a409d74959",
            "42cf68b7b302416d99cc27205ba1d7d8",
            "58b2976f940e443e83e63bec2252b307",
            "31d24404dde8446a99f6b7b81cd4d645",
            "1647f67e661641ac87fdce43d6f9cc13",
            "c7c1c9698e0143c5b7234b995468706a",
            "bb4a4564bbe94f00a1c7d11e92d230a1",
            "91ee4508c6fb420b8198f605e542451c",
            "a74eb446e5584c8da2233eee1f764cfb",
            "422c4e61c09f4be3a89499a317705682",
            "341b0b0c997a49fba6dcaa463e98d3f3",
            "46716ccec92f4f53bf8e8a974981988f",
            "10ac78a28fe64ae09a6ea68d657c60d6",
            "30087cfc889e4728831f492362be5c58",
            "c2c4ab61d42f46d5a7c009e4759a6101",
            "0451be40600f404d9dc76f0db770e1cb",
            "65b5b3a46c614a0f9a7d0a1ca24a6e79",
            "bc11742a8b314f7f9b6df4dd430e9b3e",
            "ce3df098ca8247b496afac1b6ffaed14",
            "c042b35292ad4046b3e2fd3a0c4b0379",
            "60e70b6be38a4cfea47f519a8c079036"
          ]
        },
        "id": "MAr6t69vus-N",
        "outputId": "77217d63-90f8-4de7-f39a-b4aba179cca1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.3.14: Fast Llama patching. Transformers: 4.48.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3bebecbd48d4522bab6611255a64f9f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/234 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a23b252875e242da8b7ecabaf8e08bc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/54.7k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "44c2a8346d0149f0ae67975557b65ced"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "27975910e7ce4a85a6cefd49e33f9f6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/454 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "341b0b0c997a49fba6dcaa463e98d3f3"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Llama-3.2-1B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
        "    \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "\n",
        "    \"unsloth/Llama-3.3-70B-Instruct-bnb-4bit\" # NEW! Llama 3.3 70B!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "Qy94IHVQu-Vw",
        "outputId": "453d1da9-d3c8-4083-c25f-561c922c51e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'FastLanguageModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-dbb68a7b2eed>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model, tokenizer = FastLanguageModel.from_pretrained(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mload_in_4bit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_in_4bit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'FastLanguageModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now add LoRA adapters so we only need to update 1 to 10% of all parameters!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bZsfBuZDeCL",
        "outputId": "0f6434cd-fecc-4f40-c0cd-43159e85b387"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth 2025.3.14 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
          ]
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vITh0KVJ10qX"
      },
      "source": [
        "<a name=\"Data\"></a>\n",
        "### Data Prep\n",
        "We now use the `Llama-3.1` format for conversation style finetunes. We use [Maxime Labonne's FineTome-100k](https://huggingface.co/datasets/mlabonne/FineTome-100k) dataset in ShareGPT style. But we convert it to HuggingFace's normal multiturn format `(\"role\", \"content\")` instead of `(\"from\", \"value\")`/ Llama-3 renders multi turn conversations like below:\n",
        "\n",
        "```\n",
        "<|begin_of_text|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "Hello!<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
        "\n",
        "Hey there! How are you?<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
        "\n",
        "I'm great thanks!<|eot_id|>\n",
        "```\n",
        "\n",
        "We use our `get_chat_template` function to get the correct chat template. We support `zephyr, chatml, mistral, llama, alpaca, vicuna, vicuna_old, phi3, llama3` and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "39bf1c29894f43acb6d2919e64a4fd28",
            "007a35a241b346ec9a5cdd6f3e4ddd27",
            "969a119573f942b29951ae2933e61cde",
            "b8c4d378ea0e4bcd9f572a191a7c136f",
            "7d37dd0e06724b53b4f31cc0a4321b0d",
            "4083b2ef8e6348e18b69d116508b46ff",
            "9555be409a2c4a97b18d4978ed13d35f",
            "5628ed38f304438faf5442b29a9511d6",
            "6e0fe945001140b3959e617a2f55c353",
            "0c30ded692064dc7bf36a93897f2b68f",
            "8c5ad85b4da14b239340ac95244d8ed4",
            "39684b70f2ff48cab454617c721f7777",
            "e8445e90b1054aacbecf198c7979a0b6",
            "d1cc50fb6d5849888af5d765dc51ab62",
            "2b359412d4914aa38a6e21284c12ecbc",
            "a4ceb6dbc8de4fa798ee39d28e5ebc40",
            "d6ab4d4143ff49bcae30be1bc2d76762",
            "904e7bac43bd4333b321cacfed5dcb60",
            "2bb75539976c49ed805c4ff6c58fb1d2",
            "45bc9d882a8f4a7e813245b1590d4427",
            "ddee625828cb4c22927aa73a02cd2dd9",
            "fd46f381983f49179de05497c171c805",
            "785d9147f4a341afafc5c5743892df16",
            "5e9825466cd2481b92cfe89f33b11fe3",
            "bfbb37b6f4b247b5bf5aaf7e1d80bcf9",
            "2a6ca29a76ff430d86213f910858db5b",
            "92d981a21b204f6c8b52e3caa16d1784",
            "c685f29a5d2c461ca3dda867bab6df50",
            "e2f16d56b21c4ff2918872d70e5ca847",
            "0bfbfe620ff446a0a47f7d5de7c88975",
            "5c9ee920068a47d89dbf5cbdd9e848a3",
            "95249b8fb6a84054a01f22c5f73f207b",
            "2ed2b017b9a24f36a4222c5c27753991"
          ]
        },
        "id": "LjY75GoYUCB8",
        "outputId": "94095b01-dac6-4f9c-cbc3-ca78e007ba12"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39bf1c29894f43acb6d2919e64a4fd28",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/982 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39684b70f2ff48cab454617c721f7777",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/117M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "785d9147f4a341afafc5c5743892df16",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")\n",
        "\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"latterworkschain-of-thought-reasoning\", split = \"train\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "from unsloth.chat_templates import get_chat_template\n",
        "from datasets import Dataset, load_dataset\n",
        "import torch\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r=16,\n",
        "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0,\n",
        "    bias=\"none\",\n",
        "    use_gradient_checkpointing=\"unsloth\",\n",
        "    random_state=3407,\n",
        "    use_rslora=False,\n",
        "    loftq_config=None,\n",
        ")\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template=\"llama-3.1\",\n",
        ")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False) for convo in convos]\n",
        "    return {\"text\": texts}\n",
        "\n",
        "geo_reasoning_data = [\n",
        "    {\n",
        "        \"question\": \"Where should emergency response teams be pre-positioned for disaster relief?\",\n",
        "        \"location\": {\"latitude\": 35.6895, \"longitude\": 139.6917},\n",
        "        \"cot_steps\": [\n",
        "            {\"step\": \"Identify Tokyo, Japan, as a central logistics hub.\", \"locations\": [{\"latitude\": 35.6895, \"longitude\": 139.6917}]},\n",
        "            {\"step\": \"Assess vulnerability‚Äîhigh seismic activity necessitates rapid response hubs.\", \"locations\": [{\"latitude\": 35.6895, \"longitude\": 139.6917}]},\n",
        "            {\"step\": \"Consider logistics‚Äîproximity to major transportation routes ensures accessibility.\", \"locations\": [{\"latitude\": 35.6895, \"longitude\": 139.6917}]},\n",
        "            {\"step\": \"Conclude‚ÄîTokyo is optimal for disaster response staging.\", \"locations\": [{\"latitude\": 35.6895, \"longitude\": 139.6917}]}\n",
        "        ],\n",
        "        \"answer\": \"Tokyo, Japan, due to its centralized logistics and disaster response capabilities.\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How does climate change impact alpine biodiversity?\",\n",
        "        \"location\": {\"latitude\": 46.6207, \"longitude\": 9.6719},\n",
        "        \"cot_steps\": [\n",
        "            {\"step\": \"Locate the Swiss Alps, a high-altitude region.\", \"locations\": [{\"latitude\": 46.6207, \"longitude\": 9.6719}]},\n",
        "            {\"step\": \"Evaluate biodiversity‚Äîunique species adapted to cold climates.\", \"locations\": [{\"latitude\": 46.6207, \"longitude\": 9.6719}, {\"latitude\": 46.8182, \"longitude\": 8.2275}]},\n",
        "            {\"step\": \"Analyze climate change impact‚Äîrising temperatures shift habitats upward.\", \"locations\": [{\"latitude\": 46.6207, \"longitude\": 9.6719}]},\n",
        "            {\"step\": \"Conclude‚Äîbiodiversity loss accelerates without conservation efforts.\", \"locations\": [{\"latitude\": 46.6207, \"longitude\": 9.6719}]}\n",
        "        ],\n",
        "        \"answer\": \"Biodiversity loss in the Swiss Alps accelerates without conservation efforts.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "formatted_conversations = []\n",
        "\n",
        "for entry in geo_reasoning_data:\n",
        "    formatted_conversations.append({\"role\": \"system\", \"content\": \"You are a geographic reasoning assistant.\"})\n",
        "    formatted_conversations.append({\"role\": \"user\", \"content\": f\"Analyze: {entry['question']}\"})\n",
        "\n",
        "    reasoning_steps = \"\\n\".join([\n",
        "        f\"Step {i+1}: {step['step']}\\nLocations: {', '.join([f'({loc['latitude']}, {loc['longitude']})' for loc in step['locations']])}\"\n",
        "        for i, step in enumerate(entry[\"cot_steps\"])\n",
        "    ])\n",
        "\n",
        "    assistant_response = f\"<reasoning>\\n{reasoning_steps}\\n</reasoning>\\n<answer>\\n{entry['answer']}\\n</answer>\"\n",
        "    formatted_conversations.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "dataset = Dataset.from_list(formatted_conversations)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=1024,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        max_steps=60,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=1,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])\n",
        "\n",
        "space = tokenizer(\" \", add_special_tokens=False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])\n",
        "\n",
        "trainer_stats = trainer.train()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "vJ5eO4zbxiKj",
        "outputId": "83e996d4-06fb-4a70-9610-bcfc51105df7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "f-string: f-string: unmatched '[' (<ipython-input-7-6c1deb62f200>, line 63)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-6c1deb62f200>\"\u001b[0;36m, line \u001b[0;32m63\u001b[0m\n\u001b[0;31m    f\"Step {i+1}: {step['step']}\\nLocations: {', '.join([f'({loc['latitude']}, {loc['longitude']})' for loc in step['locations']])}\"\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: f-string: unmatched '['\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9CBpiISFa6C"
      },
      "source": [
        "We now use `standardize_sharegpt` to convert ShareGPT style datasets into HuggingFace's generic format. This changes the dataset from looking like:\n",
        "```\n",
        "{\"from\": \"system\", \"value\": \"You are an assistant\"}\n",
        "{\"from\": \"human\", \"value\": \"What is 2+2?\"}\n",
        "{\"from\": \"gpt\", \"value\": \"It's 4.\"}\n",
        "```\n",
        "to\n",
        "```\n",
        "{\"role\": \"system\", \"content\": \"You are an assistant\"}\n",
        "{\"role\": \"user\", \"content\": \"What is 2+2?\"}\n",
        "{\"role\": \"assistant\", \"content\": \"It's 4.\"}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "oPXzJZzHEgXe",
        "outputId": "14053e1f-f7d3-4b99-b843-9d609e04734b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "f-string: f-string: unmatched '[' (<ipython-input-8-e6fe80625c79>, line 66)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-e6fe80625c79>\"\u001b[0;36m, line \u001b[0;32m66\u001b[0m\n\u001b[0;31m    f\"Step {i+1}: {step['step']}\\nLocations: {', '.join([f'({loc['latitude']}, {loc['longitude']})' for loc in step['locations']])}\"\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: f-string: unmatched '['\n"
          ]
        }
      ],
      "source": [
        "from unsloth.chat_templates import standardize_sharegpt\n",
        "dataset = standardize_sharegpt(dataset)\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndDUB23CGAC5"
      },
      "source": [
        "We look at how the conversations are structured for item 5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "gGFzmplrEy9I",
        "outputId": "546790cc-7e97-4db7-8f04-502968ac8cdf"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "f-string: f-string: unmatched '[' (<ipython-input-9-e6fe80625c79>, line 66)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-e6fe80625c79>\"\u001b[0;36m, line \u001b[0;32m66\u001b[0m\n\u001b[0;31m    f\"Step {i+1}: {step['step']}\\nLocations: {', '.join([f'({loc['latitude']}, {loc['longitude']})' for loc in step['locations']])}\"\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: f-string: unmatched '['\n"
          ]
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "from unsloth.chat_templates import get_chat_template, train_on_responses_only\n",
        "from datasets import Dataset\n",
        "import json\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "# Use the geo reasoning data from the provided example\n",
        "geo_reasoning_data = [\n",
        "    {\n",
        "        \"question\": \"Where should emergency response teams be pre-positioned for disaster relief?\",\n",
        "        \"location\": {\"latitude\": 35.6895, \"longitude\": 139.6917},\n",
        "        \"cot_steps\": [\n",
        "            {\"step\": \"Identify Tokyo, Japan, as a central logistics hub.\", \"locations\": [{\"latitude\": 35.6895, \"longitude\": 139.6917}]},\n",
        "            {\"step\": \"Assess vulnerability‚Äîhigh seismic activity necessitates rapid response hubs.\", \"locations\": [{\"latitude\": 35.6895, \"longitude\": 139.6917}]},\n",
        "            {\"step\": \"Consider logistics‚Äîproximity to major transportation routes ensures accessibility.\", \"locations\": [{\"latitude\": 35.6895, \"longitude\": 139.6917}]},\n",
        "            {\"step\": \"Conclude‚ÄîTokyo is optimal for disaster response staging.\", \"locations\": [{\"latitude\": 35.6895, \"longitude\": 139.6917}]}\n",
        "        ],\n",
        "        \"answer\": \"Tokyo, Japan, due to its centralized logistics and disaster response capabilities.\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How does climate change impact alpine biodiversity?\",\n",
        "        \"location\": {\"latitude\": 46.6207, \"longitude\": 9.6719},\n",
        "        \"cot_steps\": [\n",
        "            {\"step\": \"Locate the Swiss Alps, a high-altitude region.\", \"locations\": [{\"latitude\": 46.6207, \"longitude\": 9.6719}]},\n",
        "            {\"step\": \"Evaluate biodiversity‚Äîunique species adapted to cold climates.\", \"locations\": [{\"latitude\": 46.6207, \"longitude\": 9.6719}, {\"latitude\": 46.8182, \"longitude\": 8.2275}]},\n",
        "            {\"step\": \"Analyze climate change impact‚Äîrising temperatures shift habitats upward.\", \"locations\": [{\"latitude\": 46.6207, \"longitude\": 9.6719}]},\n",
        "            {\"step\": \"Conclude‚Äîbiodiversity loss accelerates without conservation efforts.\", \"locations\": [{\"latitude\": 46.6207, \"longitude\": 9.6719}]}\n",
        "        ],\n",
        "        \"answer\": \"Biodiversity loss in the Swiss Alps accelerates without conservation efforts.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "formatted_conversations = []\n",
        "\n",
        "for entry in geo_reasoning_data:\n",
        "    conversation = []\n",
        "    conversation.append({\"role\": \"system\", \"content\": \"You are a geographic reasoning assistant.\"})\n",
        "    conversation.append({\"role\": \"user\", \"content\": f\"Analyze: {entry['question']}\"})\n",
        "\n",
        "    reasoning_steps = \"\\n\".join([\n",
        "        f\"Step {i+1}: {step['step']}\\nLocations: {', '.join([f'({loc['latitude']}, {loc['longitude']})' for loc in step['locations']])}\"\n",
        "        for i, step in enumerate(entry[\"cot_steps\"])\n",
        "    ])\n",
        "\n",
        "    assistant_response = f\"<reasoning>\\n{reasoning_steps}\\n</reasoning>\\n\\nAnswer: {entry['answer']}\"\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "    formatted_conversations.append({\"conversations\": conversation})\n",
        "\n",
        "# Create dataset directly from the formatted conversations\n",
        "dataset = Dataset.from_list(formatted_conversations)\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,  # Keeps geographic information intact\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        max_steps=60,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=1,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Train on both user and assistant content to preserve geographic context\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part=\"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part=\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        "    include_instruction_loss=True  # Include user messages in loss calculation\n",
        ")\n",
        "\n",
        "# Inspect tokenization\n",
        "tokenizer.decode(trainer.train_dataset[0][\"input_ids\"])\n",
        "space = tokenizer(\" \", add_special_tokens=False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[0][\"labels\"]])\n",
        "\n",
        "# Train the model\n",
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/davendw49/sciparser.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHj-cEaAx-8p",
        "outputId": "bc5bfcbe-0a7a-493f-b30c-6959ca289295"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sciparser'...\n",
            "remote: Enumerating objects: 87, done.\u001b[K\n",
            "remote: Counting objects: 100% (23/23), done.\u001b[K\n",
            "remote: Compressing objects: 100% (19/19), done.\u001b[K\n",
            "remote: Total 87 (delta 5), reused 19 (delta 3), pack-reused 64 (from 1)\u001b[K\n",
            "Receiving objects: 100% (87/87), 115.48 MiB | 15.50 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfzTdMtvGE6w"
      },
      "source": [
        "And we see how the chat template transformed these conversations.\n",
        "\n",
        "**[Notice]** Llama 3.1 Instruct's default chat template default adds `\"Cutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\"`, so do not be alarmed!"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "from unsloth.chat_templates import get_chat_template, train_on_responses_only\n",
        "from datasets import Dataset\n",
        "import json\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "\n",
        "def formatting_prompts_func(examples):\n",
        "    convos = examples[\"conversations\"]\n",
        "    texts = [tokenizer.apply_chat_template(convo, tokenize = False, add_generation_prompt = False) for convo in convos]\n",
        "    return { \"text\" : texts, }\n",
        "\n",
        "# Use the geo reasoning data from the provided example\n",
        "geo_reasoning_data = [\n",
        "    {\n",
        "        \"question\": \"Where should emergency response teams be pre-positioned for disaster relief?\",\n",
        "        \"location\": {\"latitude\": 35.6895, \"longitude\": 139.6917},\n",
        "        \"cot_steps\": [\n",
        "            {\"step\": \"Identify Tokyo, Japan, as a central logistics hub.\", \"locations\": [{\"latitude\": 35.6895, \"longitude\": 139.6917}]},\n",
        "            {\"step\": \"Assess vulnerability‚Äîhigh seismic activity necessitates rapid response hubs.\", \"locations\": [{\"latitude\": 35.6895, \"longitude\": 139.6917}]},\n",
        "            {\"step\": \"Consider logistics‚Äîproximity to major transportation routes ensures accessibility.\", \"locations\": [{\"latitude\": 35.6895, \"longitude\": 139.6917}]},\n",
        "            {\"step\": \"Conclude‚ÄîTokyo is optimal for disaster response staging.\", \"locations\": [{\"latitude\": 35.6895, \"longitude\": 139.6917}]}\n",
        "        ],\n",
        "        \"answer\": \"Tokyo, Japan, due to its centralized logistics and disaster response capabilities.\"\n",
        "    },\n",
        "    {\n",
        "        \"question\": \"How does climate change impact alpine biodiversity?\",\n",
        "        \"location\": {\"latitude\": 46.6207, \"longitude\": 9.6719},\n",
        "        \"cot_steps\": [\n",
        "            {\"step\": \"Locate the Swiss Alps, a high-altitude region.\", \"locations\": [{\"latitude\": 46.6207, \"longitude\": 9.6719}]},\n",
        "            {\"step\": \"Evaluate biodiversity‚Äîunique species adapted to cold climates.\", \"locations\": [{\"latitude\": 46.6207, \"longitude\": 9.6719}, {\"latitude\": 46.8182, \"longitude\": 8.2275}]},\n",
        "            {\"step\": \"Analyze climate change impact‚Äîrising temperatures shift habitats upward.\", \"locations\": [{\"latitude\": 46.6207, \"longitude\": 9.6719}]},\n",
        "            {\"step\": \"Conclude‚Äîbiodiversity loss accelerates without conservation efforts.\", \"locations\": [{\"latitude\": 46.6207, \"longitude\": 9.6719}]}\n",
        "        ],\n",
        "        \"answer\": \"Biodiversity loss in the Swiss Alps accelerates without conservation efforts.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "formatted_conversations = []\n",
        "\n",
        "for entry in geo_reasoning_data:\n",
        "    conversation = []\n",
        "    conversation.append({\"role\": \"system\", \"content\": \"You are a geographic reasoning assistant.\"})\n",
        "    conversation.append({\"role\": \"user\", \"content\": f\"Analyze: {entry['question']}\"})\n",
        "\n",
        "    reasoning_steps = []\n",
        "    for i, step in enumerate(entry[\"cot_steps\"]):\n",
        "        locations_text = \", \".join([f\"({loc['latitude']}, {loc['longitude']})\" for loc in step[\"locations\"]])\n",
        "        reasoning_steps.append(f\"Step {i+1}: {step['step']}\\nLocations: {locations_text}\")\n",
        "    reasoning_steps = \"\\n\".join(reasoning_steps)\n",
        "\n",
        "    assistant_response = f\"<reasoning>\\n{reasoning_steps}\\n</reasoning>\\n\\nAnswer: {entry['answer']}\"\n",
        "    conversation.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
        "\n",
        "    formatted_conversations.append({\"conversations\": conversation})\n",
        "\n",
        "# Create dataset directly from the formatted conversations\n",
        "dataset = Dataset.from_list(formatted_conversations)\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    train_dataset=dataset,\n",
        "    dataset_text_field=\"text\",\n",
        "    max_seq_length=max_seq_length,\n",
        "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer),\n",
        "    dataset_num_proc=2,\n",
        "    packing=False,  # Keeps geographic information intact\n",
        "    args=TrainingArguments(\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=4,\n",
        "        warmup_steps=5,\n",
        "        max_steps=60,\n",
        "        learning_rate=2e-4,\n",
        "        fp16=not is_bfloat16_supported(),\n",
        "        bf16=is_bfloat16_supported(),\n",
        "        logging_steps=1,\n",
        "        optim=\"adamw_8bit\",\n",
        "        weight_decay=0.01,\n",
        "        lr_scheduler_type=\"linear\",\n",
        "        seed=3407,\n",
        "        output_dir=\"outputs\",\n",
        "        report_to=\"none\",\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Train on responses but we're using the full dataset with geographic context\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part=\"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part=\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
        ")\n",
        "\n",
        "# Inspect tokenization\n",
        "tokenizer.decode(trainer.train_dataset[0][\"input_ids\"])\n",
        "space = tokenizer(\" \", add_special_tokens=False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[0][\"labels\"]])\n",
        "\n",
        "# Train the model\n",
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ca0bca9eda354fb7ab562c35fe54b473",
            "05e456d6dc7a4fb7b758a48df122c1b6",
            "e337088d0bb44c83a22b39f34b80e5d3",
            "00ed61c29edc478194e71b55bd4cd077",
            "7154c3aa2e524d4a9ed615546b419937",
            "9a695addc5354c33b5678304dd8549f1",
            "e6b1aac504c84b3caeec68d0231805e3",
            "271c4384fd524cea94ee6cb4fb74a60d",
            "7b121d938983459d9282273d14517b6d",
            "4515f11c1498428bacf5d142e6311f11",
            "a30b2456a6fa41439b369f5434b909ef",
            "b6b54416c3b545db947ed0b9fa4baa0d",
            "73c0bc0d709b413e904d6857769dfc96",
            "d51479062aa14825bc20e0cfe6ed60f9",
            "3d3e3ad20dae43a8a37efcad87c59895",
            "46a267a5cec94d51b41adda948f951f7",
            "19a3803841b44d0dacd0428e306fbb6c",
            "dc1a22a639174a8cbc67cfd89e516415",
            "cdd4a493ad744db09065916ab8fb4f1d",
            "54f5a7d03af744a587f8d0dbb11c656c",
            "1120851b9cb143218b2804121a76ef93",
            "ffa71351783b422092a617d228ad37b3",
            "48207920e8cc49108ef55db3c5696c22",
            "260abbf8ac3c4fdca89250f1234c1244",
            "acc6c94d30374d839d1174e58999f493",
            "c8736d64f08f43ae922b363bf6ec48ac",
            "c923cb9967094b5eb73d19e250540ec0",
            "219d4b2f08794c238684228d4b37d1f9",
            "c69e11a019c2409783b13295b7fcba68",
            "0939b902c29a4a149b9f422ea78bf46a",
            "dbff3be816774f7b86031fb6e22d93c7",
            "313777fe2c1b465c9bf71e410a77492b",
            "2a1a4f2ed5044499b68e8614ce578100"
          ]
        },
        "id": "VRG7NdeKyZtV",
        "outputId": "86fed13c-6a49-4465-cc77-4f661e3e86e0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unsloth: Already have LoRA adapters! We shall skip this step.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca0bca9eda354fb7ab562c35fe54b473"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: We found double BOS tokens - we shall remove one automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6b54416c3b545db947ed0b9fa4baa0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48207920e8cc49108ef55db3c5696c22"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
            "   \\\\   /|    Num examples = 2 | Num Epochs = 60 | Total steps = 60\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
            "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
            " \"-____-\"     Trainable parameters = 24,313,856/3,000,000,000 (0.81% trained)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 00:54, Epoch 60/60]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.865300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.865300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.834300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.708600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.521000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.316600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>1.122400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.890500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.658900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.456600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.289300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.166700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.088800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.036400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.014500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.008000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.004100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.002900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.001200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.000600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.000200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Will smartly offload gradients to save VRAM!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "vhXv0xFMGNKE",
        "outputId": "07bf64e3-4c5c-430e-e4d5-3ed3cdf21b81"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAstronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "edataset[5][\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "c1e49bfdf85b43e7a42a65712bb876cb",
            "7837a0671e8546b2a8ace84dcb5ae2af",
            "bec95b1e7a4b47e4a67bb2932352a8a0",
            "276570531ad446a7b5de3539e8b87625",
            "abb7ddc7afba4ffea30e93f87ba8e2a4",
            "e5155429e2944e76950680b290468e12",
            "0480cb2de44d4b21b342843d76010c37",
            "1e1b1400f90d45bfaec92c8f95fc4dd3",
            "d814c5aec07c4f1591196168717818e0",
            "011ecf7a5d25466cb816accbd585d08d",
            "0956044f839046c6a69202f909cfac6d",
            "ddcff4e758154ab891899c687b455c7c",
            "b8cb5fc1745549fead153bdac67d4140",
            "ccfecaa184fa453790a20478fece886a",
            "12e7e7b8c35d493791916008731c64b3",
            "2fcea7f999744e9fb1aae8fc5da1d020",
            "e23ebe2499024759a5dab02bc81cf18f",
            "26fb0ec96df44a28931ee181720f5e21",
            "2f45e7900bad4d36b1ed812d61731d4f",
            "494fd190eac14dc4a48de1b5e3148dd3",
            "b16dfcef3bb64d2fa16c6f1b0ee6a0bf",
            "f792a4bf33754f3cb6cf6f43276a7924"
          ]
        },
        "id": "95_Nn-89DhsL",
        "outputId": "59591900-8871-4397-8af6-50e0f945faae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: We found double BOS tokens - we shall remove one automatically.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Unsloth: Tokenizing [\"text\"] (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1e49bfdf85b43e7a42a65712bb876cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map (num_proc=2):   0%|          | 0/2 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ddcff4e758154ab891899c687b455c7c"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, DataCollatorForSeq2Seq\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")\n",
        "\n",
        "\n",
        "#old code = We also use Unsloth's train_on_completions method to only train on the assistant outputs and ignore the loss on the user's inputs.\n",
        "\n",
        "#we dont want to do this because both contain geo rich informatin\n",
        "[ ]\n",
        "\n",
        "#update\n",
        "\n",
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_sGp5XlG6dq"
      },
      "source": [
        "We also use Unsloth's `train_on_completions` method to only train on the assistant outputs and ignore the loss on the user's inputs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "6064feeea79040409e18a1e2a289b09a",
            "bb241a26ca4d4d7186ba46cda1f8a802",
            "c9abb42da1734388a7d2f1a06832ecc6",
            "7c3a37494e5848b9994b37a4c8bac132",
            "c668ae4c7d174f2dad3fb837ff873e57",
            "dd30f3ead6394317be5a72aa890adfb9",
            "1e4ea03959b3496f8e75cc3588cf347c",
            "d356b597dda14c7ab023403ee6959cf8",
            "870ff8f17c7b47ec8d49cac84216b04c",
            "d5cfa138483f4007b2a95be833043235",
            "6d52daf29c90402a9762acdde765713f"
          ]
        },
        "id": "juQiExuBG5Bt",
        "outputId": "dca88e73-ac69-4199-9c83-cb6300e8ce9a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6064feeea79040409e18a1e2a289b09a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/100000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#old code = We also use Unsloth's train_on_completions method to only train on the assistant outputs and ignore the loss on the user's inputs.\n",
        "\n",
        "#we dont want to do this because both contain geo rich informatin\n",
        "[ ]\n",
        "\n",
        "#update\n",
        "\n",
        "from unsloth.chat_templates import train_on_responses_only\n",
        "trainer = train_on_responses_only(\n",
        "    trainer,\n",
        "    instruction_part = \"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
        "    response_part = \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv1NBUozV78l"
      },
      "source": [
        "We verify masking is actually done:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "LtsMVtlkUhja",
        "outputId": "84735ea5-8489-4a34-f501-afe91901d542"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nHow do astronomers determine the original wavelength of light emitted by a celestial body at rest, which is necessary for measuring its speed using the Doppler effect?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nAstronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "_rD6fl8EUxnG",
        "outputId": "7b0d0ab4-06c3-4f2c-bb94-0ec853a4d0cc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'                                                                \\n\\nAstronomers make use of the unique spectral fingerprints of elements found in stars. These elements emit and absorb light at specific, known wavelengths, forming an absorption spectrum. By analyzing the light received from distant stars and comparing it to the laboratory-measured spectra of these elements, astronomers can identify the shifts in these wavelengths due to the Doppler effect. The observed shift tells them the extent to which the light has been redshifted or blueshifted, thereby allowing them to calculate the speed of the star along the line of sight relative to Earth.<|eot_id|>'"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])\n",
        "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3enWUM0jV-jV"
      },
      "source": [
        "We can see the System and Instruction prompts are successfully masked!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ejIt2xSNKKp",
        "outputId": "ac07343f-67db-44e4-f9d3-83539724e6af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU = Tesla T4. Max memory = 14.748 GB.\n",
            "2.635 GB of memory reserved.\n"
          ]
        }
      ],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yqxqAZ7KJ4oL",
        "outputId": "fb3dc2a2-5cd6-4aa0-dfc5-ad734359f397"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
            "   \\\\   /|    Num examples = 100,000 | Num Epochs = 1\n",
            "O^O/ \\_/ \\    Batch size per device = 2 | Gradient Accumulation steps = 4\n",
            "\\        /    Total batch size = 8 | Total steps = 60\n",
            " \"-____-\"     Number of trainable parameters = 24,313,856\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 07:12, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.826200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.811700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.132200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.927300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.775200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.967900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.630600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>1.027400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.788400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.753300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.841900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.965600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.914400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.674500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.815000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.617800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>1.036200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.782800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.817000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.952500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.731900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.742500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.942600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.881000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.648800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.803100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.814900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.768900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.974300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.894600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.656200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.539600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.657700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.552900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.749700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.845200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.877400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.714900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.731400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.980200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.755500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.941300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.819900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.826300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.762400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.941000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.806900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.609200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.974600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.055500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.561200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.998100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>1.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.686900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>1.043900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>1.140300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.683900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.810200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.796500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.832400</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "tokenizer.decode(trainer.train_dataset[5][\"input_ids\"])\n",
        "space = tokenizer(\" \", add_special_tokens = False).input_ids[0]\n",
        "tokenizer.decode([space if x == -100 else x for x in trainer.train_dataset[5][\"labels\"]])\n",
        "\n",
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pCqnaKmlO1U9",
        "outputId": "fcbecf7f-b8a1-45d5-f415-eec2bdf96576"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "446.5262 seconds used for training.\n",
            "7.44 minutes used for training.\n",
            "Peak reserved memory = 6.531 GB.\n",
            "Peak reserved memory for training = 3.896 GB.\n",
            "Peak reserved memory % of max memory = 44.284 %.\n",
            "Peak reserved memory for training % of max memory = 26.417 %.\n"
          ]
        }
      ],
      "source": [
        "# @title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory / max_memory * 100, 3)\n",
        "lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(\n",
        "    f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\"\n",
        ")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "Let's run the model! You can change the instruction and input - leave the output blank!\n",
        "\n",
        "**[NEW] Try 2x faster inference in a free Colab for Llama-3.1 8b Instruct [here](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)**\n",
        "\n",
        "We use `min_p = 0.1` and `temperature = 1.5`. Read this [Tweet](https://x.com/menhguin/status/1826132708508213629) for more information on why."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kR3gIAX-SM2q",
        "outputId": "c996d005-a773-4c6e-f3bf-2eeb16d4b62a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nCutting Knowledge Date: December 2023\\nToday Date: 26 July 2024\\n\\n<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\nContinue the transgressive sequence: Ocean, <|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\nI can't provide information or guidance on transgressive activities. Can I help you with something else?<|eot_id|>\"]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "from unsloth.chat_templates import get_chat_template\n",
        "\n",
        "tokenizer = get_chat_template(\n",
        "    tokenizer,\n",
        "    chat_template = \"llama-3.1\",\n",
        ")\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Continue the transgressive sequence: Ocean, \"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "outputs = model.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n",
        "                         temperature = 1.5, min_p = 0.1)\n",
        "tokenizer.batch_decode(outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CrSvZObor0lY"
      },
      "source": [
        " You can also use a `TextStreamer` for continuous inference - so you can see the generation token by token, instead of waiting the whole time!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2pEuRb1r2Vg",
        "outputId": "01a41092-de06-4a0d-a828-329794a2aa2c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<reasoning>\n",
            "Step 1: Identify Tokyo, Japan, as a high-energy city.\n",
            "Locations: (35.6895, 139.6917)\n",
            "Step 2: Evaluate carnival significance‚Äîhigh‚Äîunique to Mardi Gras events.\n",
            "Locations: (35.6895, 139.6917)\n",
            "Step 3: Consider alternative locations‚ÄîNew Orleans, Louisiana, is primary.\n",
            "Locations: (29.7752, 90.0692)\n",
            "Step 4: Conclude‚ÄîNew Orleans is the cognitive dissonance resolution.\n",
            "Locations: (29.7752, 90.0692)\n",
            "</reason\n"
          ]
        }
      ],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Whats a place where they love carnival but not in europe \"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from tqdm.auto import tqdm\n",
        "import random\n",
        "import math\n",
        "import json\n",
        "from typing import List, Dict, Tuple, Union, Optional, Any\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, CLIPTokenizer\n",
        "from geoclip import GeoCLIP, LocationEncoder\n",
        "\n",
        "class GeoNut:\n",
        "    \"\"\"\n",
        "    GeoNut: Geographic neural reasoning with GeoCLIP-enhanced LLM\n",
        "    Combines GeoCLIP's location embeddings with LLM for geographic reasoning\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        llm_model_id: str = \"meta-llama/Llama-3.1-1B-Instruct\",\n",
        "        projector_path: Optional[str] = None,\n",
        "        device: Optional[str] = None,\n",
        "        use_fp16: bool = True,\n",
        "        cache_dir: Optional[str] = None\n",
        "    ):\n",
        "        # Set device intelligently\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Initialize GeoCLIP for both location and text encoding\n",
        "        print(\"Loading GeoCLIP model...\")\n",
        "        self.geoclip = GeoCLIP().to(self.device)\n",
        "        self.clip_tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\", cache_dir=cache_dir)\n",
        "        print(\"GeoCLIP loaded successfully\")\n",
        "\n",
        "        # Initialize LLM\n",
        "        print(f\"Loading LLM: {llm_model_id}\")\n",
        "        dtype = torch.float16 if use_fp16 and \"cuda\" in self.device else torch.float32\n",
        "        self.llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_id, cache_dir=cache_dir)\n",
        "\n",
        "        model_kwargs = {\n",
        "            \"device_map\": \"auto\",\n",
        "            \"torch_dtype\": dtype,\n",
        "        }\n",
        "\n",
        "        if \"cuda\" in self.device:\n",
        "            # Only use flash attention if available\n",
        "            try:\n",
        "                from flash_attn import __version__\n",
        "                model_kwargs[\"attn_implementation\"] = \"flash_attention_2\"\n",
        "                print(\"Using Flash Attention 2\")\n",
        "            except ImportError:\n",
        "                print(\"Flash Attention not available, using default attention\")\n",
        "\n",
        "        self.llm = AutoModelForCausalLM.from_pretrained(\n",
        "            llm_model_id,\n",
        "            cache_dir=cache_dir,\n",
        "            **model_kwargs\n",
        "        )\n",
        "        print(\"LLM loaded successfully\")\n",
        "\n",
        "        # If model has no pad token, set it to eos token\n",
        "        if self.llm_tokenizer.pad_token is None:\n",
        "            self.llm_tokenizer.pad_token = self.llm_tokenizer.eos_token\n",
        "\n",
        "        # Layer to project from GeoCLIP space (512d) to LLM hidden space\n",
        "        self.llm_dim = self.llm.config.hidden_size\n",
        "        self.projection = nn.Linear(512, self.llm_dim).to(self.device)\n",
        "\n",
        "        # Initialize with reasonable scaling\n",
        "        nn.init.normal_(self.projection.weight, std=0.02)\n",
        "        nn.init.zeros_(self.projection.bias)\n",
        "\n",
        "        # Load pre-trained projector if available\n",
        "        if projector_path and os.path.exists(projector_path):\n",
        "            print(f\"Loading projector weights from {projector_path}\")\n",
        "            self.projection.load_state_dict(torch.load(projector_path, map_location=self.device))\n",
        "\n",
        "        # System prompt for geographic reasoning\n",
        "        self.geo_system_prompt = \"\"\"You are GeoNut, an advanced geographic reasoning system with deep understanding of physical and human geography.\n",
        "\n",
        "When analyzing geographic questions, you:\n",
        "1. Consider the precise spatial relationships between locations and regions\n",
        "2. Analyze physical geography factors (landforms, climate, ecosystems, natural resources)\n",
        "3. Examine human geography elements (settlement patterns, land use, cultural landscapes)\n",
        "4. Explore interactions between physical environments and human activities\n",
        "5. Apply geographic principles like spatial distribution, diffusion, and human-environment interaction\n",
        "6. Consider multiple scales from local to global\n",
        "\n",
        "Provide comprehensive geographic explanations that reveal deeper insights about spatial relationships and geographic systems. Your analysis should demonstrate expert geographic knowledge and reasoning.\"\"\"\n",
        "\n",
        "        # Flag to control visualization features\n",
        "        self.enable_visualizations = False\n",
        "\n",
        "        # Cache for repeated location lookups\n",
        "        self._location_embedding_cache = {}\n",
        "\n",
        "    def enable_visualization(self, enable: bool = True):\n",
        "        \"\"\"Toggle visualization features on/off\"\"\"\n",
        "        self.enable_visualizations = enable\n",
        "        return self\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def encode_location(self, coords: Tuple[float, float]) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Encode a location using GeoCLIP\n",
        "\n",
        "        Args:\n",
        "            coords: (latitude, longitude) tuple\n",
        "\n",
        "        Returns:\n",
        "            GeoCLIP embedding tensor\n",
        "        \"\"\"\n",
        "        # Check cache for this location\n",
        "        cache_key = f\"{coords[0]:.5f},{coords[1]:.5f}\"\n",
        "        if cache_key in self._location_embedding_cache:\n",
        "            return self._location_embedding_cache[cache_key]\n",
        "\n",
        "        coords_tensor = torch.tensor([[coords[0], coords[1]]], dtype=torch.float32).to(self.device)\n",
        "        embedding = self.geoclip.location_encoder(coords_tensor)\n",
        "\n",
        "        # Normalize\n",
        "        embedding = F.normalize(embedding, p=2, dim=1)\n",
        "\n",
        "        # Cache this embedding\n",
        "        self._location_embedding_cache[cache_key] = embedding\n",
        "\n",
        "        return embedding\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def encode_text(self, text: str) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Encode text using GeoCLIP's text pathway\n",
        "\n",
        "        Args:\n",
        "            text: Text to encode\n",
        "\n",
        "        Returns:\n",
        "            GeoCLIP-aligned text embedding\n",
        "        \"\"\"\n",
        "        # Process text through GeoCLIP's text encoding pathway\n",
        "        inputs = self.clip_tokenizer(text, return_tensors=\"pt\", padding=True).to(self.device)\n",
        "\n",
        "        # Get CLIP text features and pass through GeoCLIP's alignment MLP\n",
        "        text_features = self.geoclip.image_encoder.mlp(\n",
        "            self.geoclip.image_encoder.CLIP.get_text_features(**inputs)\n",
        "        )\n",
        "        # Normalize the features (as done in GeoCLIP)\n",
        "        text_features = F.normalize(text_features, p=2, dim=1)\n",
        "\n",
        "        return text_features\n",
        "\n",
        "    def inject_geographic_knowledge(\n",
        "        self,\n",
        "        text_query: str,\n",
        "        coords_list: Optional[List[Tuple[float, float]]] = None,\n",
        "        lambda_factor: float = 0.1,\n",
        "        injection_layers: Optional[List[int]] = None\n",
        "    ) -> List:\n",
        "        \"\"\"\n",
        "        Prepare hooks to inject geographic embeddings into LLM\n",
        "\n",
        "        Args:\n",
        "            text_query: Geographic query text\n",
        "            coords_list: Optional list of (latitude, longitude) tuples\n",
        "            lambda_factor: Scaling factor for injected embeddings\n",
        "            injection_layers: Specific layers to inject into (defaults to last 3)\n",
        "\n",
        "        Returns:\n",
        "            List of hooks for LLM injection\n",
        "        \"\"\"\n",
        "        hooks = []\n",
        "\n",
        "        # Encode text using GeoCLIP's text pathway\n",
        "        text_embedding = self.encode_text(text_query)\n",
        "\n",
        "        # Encode locations if provided\n",
        "        location_embeddings = []\n",
        "        if coords_list:\n",
        "            for coords in coords_list:\n",
        "                embedding = self.encode_location(coords)\n",
        "                location_embeddings.append(embedding)\n",
        "\n",
        "        # Combine embeddings - if we have both text and locations, average them\n",
        "        if location_embeddings:\n",
        "            # Concatenate location embeddings and average them\n",
        "            locations_combined = torch.cat(location_embeddings, dim=0)\n",
        "            locations_avg = torch.mean(locations_combined, dim=0, keepdim=True)\n",
        "\n",
        "            # Average with text embedding\n",
        "            combined_embedding = (text_embedding + locations_avg) / 2\n",
        "        else:\n",
        "            # Use only text embedding if no locations\n",
        "            combined_embedding = text_embedding\n",
        "\n",
        "        # Project to LLM dimension\n",
        "        projected_embedding = self.projection(combined_embedding)\n",
        "\n",
        "        # Scale the embedding\n",
        "        projected_embedding = lambda_factor * projected_embedding\n",
        "\n",
        "        # Determine which layers to inject to\n",
        "        num_layers = len(self.llm.model.layers)\n",
        "        if injection_layers is None:\n",
        "            # Default to last 3 layers\n",
        "            injection_layers = [num_layers-i-1 for i in range(3)]\n",
        "\n",
        "        # Register hooks for injection\n",
        "        for layer_idx in injection_layers:\n",
        "            if layer_idx < 0 or layer_idx >= num_layers:\n",
        "                print(f\"Warning: Layer index {layer_idx} out of bounds, skipping\")\n",
        "                continue\n",
        "\n",
        "            layer = self.llm.model.layers[layer_idx]\n",
        "\n",
        "            # Register hook to modify the layer's output\n",
        "            hook = layer.register_forward_hook(\n",
        "                lambda mod, inp, out, vec=projected_embedding:\n",
        "                    (out[0] + vec, *out[1:]) if isinstance(out, tuple) else out + vec\n",
        "            )\n",
        "            hooks.append(hook)\n",
        "\n",
        "        return hooks\n",
        "\n",
        "    def generate_response(\n",
        "        self,\n",
        "        messages: List[Dict[str, str]],\n",
        "        coords_list: Optional[List[Tuple[float, float]]] = None,\n",
        "        lambda_factor: float = 0.1,\n",
        "        max_new_tokens: int = 1024,\n",
        "        temperature: float = 0.7,\n",
        "        top_p: float = 0.9,\n",
        "        injection_layers: Optional[List[int]] = None,\n",
        "    ) -> str:\n",
        "        \"\"\"\n",
        "        Generate geographic response with location-enhanced reasoning\n",
        "\n",
        "        Args:\n",
        "            messages: Chat history with \"role\" and \"content\" keys\n",
        "            coords_list: Optional list of coordinates to enhance reasoning\n",
        "            lambda_factor: Scaling factor for geographic embeddings\n",
        "            max_new_tokens: Maximum tokens to generate\n",
        "            temperature: Sampling temperature\n",
        "            top_p: Nucleus sampling parameter\n",
        "            injection_layers: Specific layers to inject into (defaults to last 3)\n",
        "\n",
        "        Returns:\n",
        "            Model response\n",
        "        \"\"\"\n",
        "        # Format messages into prompt\n",
        "        prompt = \"\"\n",
        "        if messages and messages[0][\"role\"] == \"system\":\n",
        "            system_content = messages[0][\"content\"]\n",
        "            messages = messages[1:]\n",
        "        else:\n",
        "            system_content = self.geo_system_prompt\n",
        "\n",
        "        # Get chat template if available\n",
        "        if hasattr(self.llm_tokenizer, \"apply_chat_template\"):\n",
        "            # Use the model's chat template if available (cleaner approach)\n",
        "            inputs = self.llm_tokenizer.apply_chat_template(\n",
        "                [{\"role\": \"system\", \"content\": system_content}] + messages,\n",
        "                return_tensors=\"pt\"\n",
        "            ).to(self.device)\n",
        "        else:\n",
        "            # Fallback to manual formatting if no chat template available\n",
        "            prompt += f\"<|system|>\\n{system_content}\\n<|user|>\\n\"\n",
        "\n",
        "            # Add conversation history\n",
        "            for i, msg in enumerate(messages):\n",
        "                role = msg[\"role\"]\n",
        "                content = msg[\"content\"]\n",
        "\n",
        "                if role == \"user\":\n",
        "                    if i > 0:  # Not the first message\n",
        "                        prompt += f\"\\n<|user|>\\n{content}\"\n",
        "                    else:\n",
        "                        prompt += f\"{content}\"\n",
        "                elif role == \"assistant\":\n",
        "                    prompt += f\"\\n<|assistant|>\\n{content}\"\n",
        "\n",
        "            # Add final assistant tag\n",
        "            prompt += \"\\n<|assistant|>\\n\"\n",
        "\n",
        "            # Tokenize\n",
        "            inputs = self.llm_tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        # Extract the latest user query for embedding\n",
        "        user_queries = [msg[\"content\"] for msg in messages if msg[\"role\"] == \"user\"]\n",
        "        user_query = user_queries[-1] if user_queries else None\n",
        "\n",
        "        # Set up knowledge injection if query available\n",
        "        hooks = []\n",
        "        if user_query:\n",
        "            hooks = self.inject_geographic_knowledge(\n",
        "                text_query=user_query,\n",
        "                coords_list=coords_list,\n",
        "                lambda_factor=lambda_factor,\n",
        "                injection_layers=injection_layers\n",
        "            )\n",
        "\n",
        "        # Generate response\n",
        "        with torch.no_grad():\n",
        "            output = self.llm.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                temperature=temperature,\n",
        "                top_p=top_p,\n",
        "                do_sample=True\n",
        "            )\n",
        "\n",
        "        # Remove hooks\n",
        "        for hook in hooks:\n",
        "            hook.remove()\n",
        "\n",
        "        # Decode response\n",
        "        full_response = self.llm_tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "        # Handle different models' response formats\n",
        "        if hasattr(self.llm_tokenizer, \"apply_chat_template\"):\n",
        "            # For models with chat templates, extract just the last assistant message\n",
        "            # This will depend on the specific model's chat format\n",
        "            try:\n",
        "                # Try to find the last assistant message\n",
        "                if \"<|assistant|>\" in full_response:\n",
        "                    parts = full_response.split(\"<|assistant|>\")\n",
        "                    response = parts[-1].strip()\n",
        "                else:\n",
        "                    # Default to extracting new tokens only\n",
        "                    input_length = len(self.llm_tokenizer.decode(inputs[0], skip_special_tokens=True))\n",
        "                    response = full_response[input_length:].strip()\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Error extracting assistant response: {e}\")\n",
        "                response = full_response  # Fallback to full response\n",
        "        else:\n",
        "            # Default extraction for models without chat templates\n",
        "            parts = full_response.split(\"<|assistant|>\")\n",
        "            if len(parts) > 1:\n",
        "                response = parts[-1].strip()\n",
        "            else:\n",
        "                response = full_response\n",
        "\n",
        "        return response\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def get_nearest_locations(\n",
        "        self,\n",
        "        query_text: str,\n",
        "        top_k: int = 5,\n",
        "        visualize: bool = False\n",
        "    ) -> List[Tuple[Tuple[float, float], float]]:\n",
        "        \"\"\"\n",
        "        Get the most relevant locations for a text query from GeoCLIP's GPS gallery\n",
        "\n",
        "        Args:\n",
        "            query_text: Geographic query text\n",
        "            top_k: Number of top locations to return\n",
        "            visualize: Whether to generate a visualization of the results\n",
        "\n",
        "        Returns:\n",
        "            List of ((lat, lon), similarity_score) tuples\n",
        "        \"\"\"\n",
        "        # Encode the query using GeoCLIP's text pathway\n",
        "        text_embedding = self.encode_text(query_text)\n",
        "\n",
        "        # Get GPS gallery for comparison\n",
        "        gps_gallery = self.geoclip.gps_gallery.to(self.device)\n",
        "\n",
        "        # Encode locations in gallery\n",
        "        loc_features = self.geoclip.location_encoder(gps_gallery)\n",
        "        loc_features = F.normalize(loc_features, p=2, dim=1)\n",
        "\n",
        "        # Calculate similarities\n",
        "        similarity = self.geoclip.logit_scale.exp() * (text_embedding @ loc_features.T)\n",
        "        probs = similarity.softmax(dim=-1)\n",
        "\n",
        "        # Get top matches\n",
        "        top_preds = torch.topk(probs[0], top_k)\n",
        "\n",
        "        # Convert to coordinate predictions with similarity scores\n",
        "        results = [\n",
        "            ((float(coords[0]), float(coords[1])), float(conf))\n",
        "            for coords, conf in zip(gps_gallery[top_preds.indices], top_preds.values)\n",
        "        ]\n",
        "\n",
        "        # Generate visualization if enabled\n",
        "        if visualize and self.enable_visualizations:\n",
        "            self._visualize_locations(query_text, results)\n",
        "\n",
        "        return results\n",
        "\n",
        "    def _visualize_locations(self, query: str, locations: List[Tuple[Tuple[float, float], float]]):\n",
        "        \"\"\"Generate a visualization of the locations\"\"\"\n",
        "        try:\n",
        "            import folium\n",
        "            from folium.plugins import HeatMap\n",
        "\n",
        "            # Center map on the highest confidence location\n",
        "            center_lat, center_lon = locations[0][0]\n",
        "            m = folium.Map(location=[center_lat, center_lon], zoom_start=2)\n",
        "\n",
        "            # Add markers for each location\n",
        "            for i, ((lat, lon), confidence) in enumerate(locations):\n",
        "                color = 'red' if i == 0 else 'blue' if i == 1 else 'green'\n",
        "\n",
        "                folium.Marker(\n",
        "                    [lat, lon],\n",
        "                    popup=f\"Score: {confidence:.4f}\",\n",
        "                    icon=folium.Icon(color=color)\n",
        "                ).add_to(m)\n",
        "\n",
        "            # Create filename based on query\n",
        "            filename = f\"geonut_locations_{query.replace(' ', '_')[:20]}.html\"\n",
        "            m.save(filename)\n",
        "            print(f\"Visualization saved to {filename}\")\n",
        "        except ImportError:\n",
        "            print(\"Folium not installed. Install with: pip install folium\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating visualization: {e}\")\n",
        "\n",
        "    def extract_location_features(self, coords: Tuple[float, float], vis_dims: int = 64) -> Dict:\n",
        "        \"\"\"\n",
        "        Extract and analyze features from a specific location\n",
        "\n",
        "        Args:\n",
        "            coords: (latitude, longitude) tuple\n",
        "            vis_dims: Number of dimensions to show in visualization\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of location analysis\n",
        "        \"\"\"\n",
        "        # Get the full embedding\n",
        "        embedding = self.encode_location(coords)\n",
        "\n",
        "        # Get the top dimensions by magnitude\n",
        "        values = embedding[0].cpu().numpy()\n",
        "        magnitudes = np.abs(values)\n",
        "        top_indices = np.argsort(magnitudes)[-vis_dims:][::-1]\n",
        "\n",
        "        # Create feature analysis\n",
        "        analysis = {\n",
        "            \"coordinates\": {\"lat\": coords[0], \"lon\": coords[1]},\n",
        "            \"embedding_stats\": {\n",
        "                \"mean\": float(np.mean(values)),\n",
        "                \"std\": float(np.std(values)),\n",
        "                \"min\": float(np.min(values)),\n",
        "                \"max\": float(np.max(values))\n",
        "            },\n",
        "            \"top_dimensions\": [\n",
        "                {\"index\": int(idx), \"value\": float(values[idx]), \"magnitude\": float(magnitudes[idx])}\n",
        "                for idx in top_indices\n",
        "            ]\n",
        "        }\n",
        "\n",
        "        # Create visualization if enabled\n",
        "        if self.enable_visualizations:\n",
        "            plt.figure(figsize=(10, 5))\n",
        "            plt.bar(range(vis_dims), [values[idx] for idx in top_indices])\n",
        "            plt.title(f\"Top {vis_dims} Feature Dimensions for Location ({coords[0]:.4f}, {coords[1]:.4f})\")\n",
        "            plt.xlabel(\"Feature Index\")\n",
        "            plt.ylabel(\"Feature Value\")\n",
        "            plt.tight_layout()\n",
        "\n",
        "            # Save figure\n",
        "            filename = f\"location_features_{coords[0]:.2f}_{coords[1]:.2f}.png\"\n",
        "            plt.savefig(filename)\n",
        "            plt.close()\n",
        "\n",
        "            analysis[\"visualization_path\"] = filename\n",
        "\n",
        "        return analysis\n",
        "\n",
        "    def compare_locations(\n",
        "        self,\n",
        "        coords_list: List[Tuple[float, float]],\n",
        "        labels: Optional[List[str]] = None\n",
        "    ) -> Dict:\n",
        "        \"\"\"\n",
        "        Compare multiple locations based on their GeoCLIP embeddings\n",
        "\n",
        "        Args:\n",
        "            coords_list: List of (latitude, longitude) tuples\n",
        "            labels: Optional labels for each location\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with similarity matrix and visualization data\n",
        "        \"\"\"\n",
        "        if not labels:\n",
        "            labels = [f\"Location {i+1}\" for i in range(len(coords_list))]\n",
        "\n",
        "        # Get embeddings for all locations\n",
        "        embeddings = []\n",
        "        for coords in coords_list:\n",
        "            embedding = self.encode_location(coords)\n",
        "            embeddings.append(embedding[0])\n",
        "\n",
        "        # Stack embeddings\n",
        "        embeddings_tensor = torch.stack(embeddings)\n",
        "\n",
        "        # Calculate cosine similarity matrix\n",
        "        similarity_matrix = F.cosine_similarity(\n",
        "            embeddings_tensor.unsqueeze(1),\n",
        "            embeddings_tensor.unsqueeze(0),\n",
        "            dim=2\n",
        "        ).cpu().numpy()\n",
        "\n",
        "        # Create result dictionary\n",
        "        result = {\n",
        "            \"locations\": [{\"coords\": coords, \"label\": label}\n",
        "                         for coords, label in zip(coords_list, labels)],\n",
        "            \"similarity_matrix\": similarity_matrix.tolist()\n",
        "        }\n",
        "\n",
        "        # Create visualization if enabled\n",
        "        if self.enable_visualizations:\n",
        "            try:\n",
        "                # Create heatmap of similarities\n",
        "                plt.figure(figsize=(10, 8))\n",
        "                plt.imshow(similarity_matrix, cmap='viridis', vmin=0, vmax=1)\n",
        "                plt.colorbar(label='Cosine Similarity')\n",
        "                plt.xticks(range(len(labels)), labels, rotation=45, ha=\"right\")\n",
        "                plt.yticks(range(len(labels)), labels)\n",
        "                plt.title(\"Location Similarity Matrix\")\n",
        "                plt.tight_layout()\n",
        "\n",
        "                # Save figure\n",
        "                filename = \"location_similarity_matrix.png\"\n",
        "                plt.savefig(filename)\n",
        "                plt.close()\n",
        "\n",
        "                # Also create a t-SNE visualization if we have enough locations\n",
        "                if len(coords_list) >= 4:\n",
        "                    # Apply t-SNE dimensionality reduction\n",
        "                    tsne = TSNE(n_components=2, random_state=42, perplexity=min(30, len(coords_list)-1))\n",
        "                    embeddings_2d = tsne.fit_transform(embeddings_tensor.cpu().numpy())\n",
        "\n",
        "                    # Plot in 2D space\n",
        "                    plt.figure(figsize=(10, 8))\n",
        "                    plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], s=100)\n",
        "\n",
        "                    # Add labels\n",
        "                    for i, label in enumerate(labels):\n",
        "                        plt.annotate(label, (embeddings_2d[i, 0], embeddings_2d[i, 1]),\n",
        "                                     fontsize=12, ha='right')\n",
        "\n",
        "                    plt.title(\"t-SNE Visualization of Location Embeddings\")\n",
        "                    plt.tight_layout()\n",
        "\n",
        "                    # Save figure\n",
        "                    tsne_filename = \"location_tsne.png\"\n",
        "                    plt.savefig(tsne_filename)\n",
        "                    plt.close()\n",
        "\n",
        "                    result[\"tsne_visualization_path\"] = tsne_filename\n",
        "\n",
        "                result[\"visualization_path\"] = filename\n",
        "            except Exception as e:\n",
        "                print(f\"Error creating visualization: {e}\")\n",
        "\n",
        "        return result\n",
        "\n",
        "    def export_location_embeddings(self, coords_list: List[Tuple[float, float]], output_path: str):\n",
        "        \"\"\"\n",
        "        Export location embeddings to a file\n",
        "\n",
        "        Args:\n",
        "            coords_list: List of (latitude, longitude) tuples\n",
        "            output_path: Path to save embeddings\n",
        "        \"\"\"\n",
        "        result = {}\n",
        "\n",
        "        for coords in tqdm(coords_list, desc=\"Processing locations\"):\n",
        "            embedding = self.encode_location(coords)\n",
        "            key = f\"{coords[0]:.6f},{coords[1]:.6f}\"\n",
        "            result[key] = embedding[0].cpu().numpy().tolist()\n",
        "\n",
        "        # Save to file\n",
        "        with open(output_path, 'w') as f:\n",
        "            json.dump(result, f)\n",
        "\n",
        "        print(f\"Exported {len(coords_list)} location embeddings to {output_path}\")\n",
        "\n",
        "class GeoNutTrainer:\n",
        "    \"\"\"\n",
        "    Trainer for GeoNut's embedding projector\n",
        "    Aligns GeoCLIP embeddings with LLM hidden representations\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        llm_model_id: str,\n",
        "        device: Optional[str] = None,\n",
        "        use_fp16: bool = True,\n",
        "        cache_dir: Optional[str] = None\n",
        "    ):\n",
        "        # Set device intelligently\n",
        "        self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.llm_model_id = llm_model_id\n",
        "\n",
        "        # Initialize GeoCLIP\n",
        "        print(\"Loading GeoCLIP model...\")\n",
        "        self.geoclip = GeoCLIP().to(self.device)\n",
        "        self.clip_tokenizer = CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\", cache_dir=cache_dir)\n",
        "        print(\"GeoCLIP loaded successfully\")\n",
        "\n",
        "        # Initialize LLM\n",
        "        print(f\"Loading LLM: {llm_model_id}\")\n",
        "        dtype = torch.float16 if use_fp16 and \"cuda\" in self.device else torch.float32\n",
        "        self.llm_tokenizer = AutoTokenizer.from_pretrained(llm_model_id, cache_dir=cache_dir)\n",
        "\n",
        "        model_kwargs = {\n",
        "            \"device_map\": \"auto\",\n",
        "            \"torch_dtype\": dtype,\n",
        "        }\n",
        "\n",
        "        self.llm = AutoModelForCausalLM.from_pretrained(\n",
        "            llm_model_id,\n",
        "            cache_dir=cache_dir,\n",
        "            **model_kwargs\n",
        "        )\n",
        "        print(\"LLM loaded successfully\")\n",
        "\n",
        "        # Initialize projector\n",
        "        self.llm_dim = self.llm.config.hidden_size\n",
        "        self.projection = nn.Linear(512, self.llm_dim).to(self.device)\n",
        "        nn.init.normal_(self.projection.weight, std=0.02)\n",
        "        nn.init.zeros_(self.projection.bias)\n",
        "\n",
        "        # Load comprehensive geographic context prompts\n",
        "        self.geo_contexts = [\n",
        "            \"The Mediterranean climate is characterized by hot, dry summers and mild, wet winters.\",\n",
        "            \"Mountain ranges often create rain shadows, affecting precipitation patterns on leeward sides.\",\n",
        "            \"Coastal regions typically experience milder temperatures due to the moderating influence of bodies of water.\",\n",
        "            \"Tropical rainforests are found near the equator and receive high rainfall throughout the year.\",\n",
        "            \"Urban heat islands form when natural land cover is replaced with pavement, buildings, and other surfaces that absorb heat.\",\n",
        "            \"River deltas are rich agricultural lands formed by sediment deposition over thousands of years.\",\n",
        "            \"Desert ecosystems are characterized by low precipitation and extreme temperature variations.\",\n",
        "            \"Plate tectonics create various landforms including mountains, valleys, and ocean trenches.\",\n",
        "            \"The Great Plains of North America feature extensive grasslands and are known for agriculture.\",\n",
        "            \"Permafrost regions in high latitudes are experiencing significant changes due to global warming.\"\n",
        "        ]\n",
        "\n",
        "        # Geographic questions for training\n",
        "        self.geo_questions = [\n",
        "            \"How does climate change impact coastal ecosystems?\",\n",
        "            \"What factors influence the development of urban heat islands?\",\n",
        "            \"How do mountain ranges affect regional climate patterns?\",\n",
        "            \"What are the key characteristics of Mediterranean climate zones?\",\n",
        "            \"How do river systems shape the surrounding landscape?\",\n",
        "            \"What challenges do cities in arid regions face regarding water resources?\",\n",
        "            \"How does elevation affect vegetation patterns in mountainous regions?\",\n",
        "            \"What role do wetlands play in flood control and water purification?\",\n",
        "            \"How do ocean currents influence coastal climates?\",\n",
        "            \"What factors determine the location of agricultural regions?\",\n",
        "            \"How are volcanic landforms created and what impacts do they have?\",\n",
        "            \"What ecological adaptations occur in desert environments?\",\n",
        "            \"How do human settlements impact natural ecosystems?\",\n",
        "            \"What are the characteristics of different forest biomes?\",\n",
        "            \"How do glaciers shape mountain landscapes over time?\"\n",
        "        ]\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def encode_text(self, text: str) -> torch.Tensor:\n",
        "        \"\"\"Encode text using GeoCLIP's text pathway\"\"\"\n",
        "        inputs = self.clip_tokenizer(text, return_tensors=\"pt\", padding=True).to(self.device)\n",
        "\n",
        "        # Following GeoCLIP's text encoding pathway\n",
        "        text_features = self.geoclip.image_encoder.mlp(\n",
        "            self.geoclip.image_encoder.CLIP.get_text_features(**inputs)\n",
        "        )\n",
        "        text_features = F.normalize(text_features, p=2, dim=1)\n",
        "\n",
        "        return text_features\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def encode_location(self, coords: Tuple[float, float]) -> torch.Tensor:\n",
        "        \"\"\"Encode a location using GeoCLIP\"\"\"\n",
        "        coords_tensor = torch.tensor([[coords[0], coords[1]]], dtype=torch.float32).to(self.device)\n",
        "        embedding = self.geoclip.location_encoder(coords_tensor)\n",
        "\n",
        "        # Normalize\n",
        "        embedding = F.normalize(embedding, p=2, dim=1)\n",
        "        return embedding\n",
        "\n",
        "    def get_llm_hidden_representation(\n",
        "        self,\n",
        "        prompt: str,\n",
        "        layer_idx: int = -1\n",
        "    ) -> torch.Tensor:\n",
        "        \"\"\"Get hidden representation from LLM for a prompt\"\"\"\n",
        "        inputs = self.llm_tokenizer(prompt, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        # Hook to capture hidden state\n",
        "        hidden_states = None\n",
        "\n",
        "        def hook_fn(module, inp, out):\n",
        "            nonlocal hidden_states\n",
        "            hidden_states = out[0] if isinstance(out, tuple) else out\n",
        "\n",
        "        # Register hook on specified layer\n",
        "        if layer_idx < 0:\n",
        "            # Convert negative index to positive\n",
        "            layer_idx = len(self.llm.model.layers) + layer_idx\n",
        "\n",
        "        layer = self.llm.model.layers[layer_idx]\n",
        "        hook = layer.register_forward_hook(hook_fn)\n",
        "\n",
        "        # Forward pass\n",
        "        with torch.no_grad():\n",
        "            self.llm(**inputs)\n",
        "\n",
        "        # Remove hook\n",
        "        hook.remove()\n",
        "\n",
        "        # Get last token representation\n",
        "        last_hidden = hidden_states[:, -1, :]\n",
        "\n",
        "        return last_hidden\n",
        "\n",
        "    def train_projector(\n",
        "        self,\n",
        "        num_epochs: int = 10,\n",
        "        batch_size: int = 4,\n",
        "        learning_rate: float = 1e-4,\n",
        "        output_path: str = \"geonut_projector.pt\",\n",
        "        sample_size: Optional[int] = None,\n",
        "        layers_to_sample: List[int] = [-1, -2, -3],  # Sample from multiple layers\n",
        "        validation_split: float = 0.1,  # Use some data for validation\n",
        "        early_stopping_patience: int = 3  # Stop if no improvement for N epochs\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Train the GeoCLIP to LLM projector\n",
        "\n",
        "        Args:\n",
        "            num_epochs: Number of training epochs\n",
        "            batch_size: Batch size for training\n",
        "            learning_rate: Learning rate\n",
        "            output_path: Path to save trained projector\n",
        "            sample_size: Number of locations to sample (None for all)\n",
        "            layers_to_sample: Which LLM layers to sample representations from\n",
        "            validation_split: Portion of data to use for validation\n",
        "            early_stopping_patience: Stop training if no improvement for this many epochs\n",
        "        \"\"\"\n",
        "        # Optimizer\n",
        "        optimizer = torch.optim.AdamW(self.projection.parameters(), lr=learning_rate)\n",
        "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "            optimizer, mode='min', factor=0.5, patience=1, verbose=True\n",
        "        )\n",
        "\n",
        "        # Loss function\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        # Get locations from GeoCLIP's gallery for training\n",
        "        gps_gallery = self.geoclip."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "2jxcQjYJ1NGL",
        "outputId": "32c5e4e0-f619-42c3-b2d7-7eaf686bb0fe"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-21-25d66ae831ca>, line 755)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-21-25d66ae831ca>\"\u001b[0;36m, line \u001b[0;32m755\u001b[0m\n\u001b[0;31m    gps_gallery = self.geoclip.\u001b[0m\n\u001b[0m                               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GeoReasoner:\n",
        "    \"\"\"\n",
        "    Enhanced geographic reasoning component for GeoNut\n",
        "    Implements structured geographic reasoning with step-by-step analysis\n",
        "    \"\"\"\n",
        "    def __init__(self, geonut):\n",
        "        self.geonut = geonut\n",
        "        self.reasoning_template = \"\"\"\n",
        "        <reasoning>\n",
        "        {reasoning_steps}\n",
        "        </reasoning>\n",
        "        \"\"\"\n",
        "\n",
        "    def structured_geographic_analysis(\n",
        "        self,\n",
        "        query: str,\n",
        "        max_steps: int = 4,\n",
        "        confidence_threshold: float = 0.15\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Perform structured geographic reasoning on a query\n",
        "\n",
        "        Args:\n",
        "            query: Geographic query text\n",
        "            max_steps: Maximum reasoning steps to perform\n",
        "            confidence_threshold: Minimum confidence for location consideration\n",
        "\n",
        "        Returns:\n",
        "            Dict containing reasoning steps and final locations\n",
        "        \"\"\"\n",
        "        reasoning_steps = []\n",
        "        current_locations = []\n",
        "        step_count = 0\n",
        "\n",
        "        # Initial location candidates from query\n",
        "        locations = self.geonut.get_nearest_locations(query, top_k=5)\n",
        "        top_locations = [(coords, score) for coords, score in locations if score >= confidence_threshold]\n",
        "\n",
        "        if not top_locations:\n",
        "            top_locations = locations[:2]  # Take at least 2 locations\n",
        "\n",
        "        # Format locations for first step\n",
        "        loc_text = \", \".join([f\"({lat:.4f}, {lon:.4f})\" for (lat, lon), _ in top_locations])\n",
        "        reasoning_steps.append(f\"Step 1: Identify initial locations based on query terms: '{query}'. Locations: {loc_text}\")\n",
        "        current_locations = [coords for coords, _ in top_locations]\n",
        "        step_count += 1\n",
        "\n",
        "        # Iterative refinement of locations through geographic reasoning\n",
        "        while step_count < max_steps:\n",
        "            # Prepare prompt for reasoning step\n",
        "            step_prompt = self._prepare_step_prompt(query, reasoning_steps, current_locations, step_count)\n",
        "\n",
        "            # Generate reasoning for this step\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": self._reasoning_system_prompt()},\n",
        "                {\"role\": \"user\", \"content\": step_prompt}\n",
        "            ]\n",
        "\n",
        "            # Generate LLM response with geographic knowledge injection\n",
        "            response = self.geonut.generate_response(\n",
        "                messages=messages,\n",
        "                coords_list=current_locations,\n",
        "                max_new_tokens=256\n",
        "            )\n",
        "\n",
        "            # Extract new locations if mentioned\n",
        "            new_locations = self._extract_locations_from_response(response)\n",
        "\n",
        "            # If no new locations found, try to get some based on extracted place names\n",
        "            if not new_locations:\n",
        "                place_names = self._extract_place_names(response)\n",
        "                if place_names:\n",
        "                    for place in place_names:\n",
        "                        place_locations = self.geonut.get_nearest_locations(place, top_k=1)\n",
        "                        if place_locations:\n",
        "                            new_locations.append(place_locations[0][0])\n",
        "\n",
        "            # Format structured step\n",
        "            if new_locations:\n",
        "                current_locations = new_locations\n",
        "                loc_text = \", \".join([f\"({lat:.4f}, {lon:.4f})\" for lat, lon in current_locations])\n",
        "            else:\n",
        "                loc_text = \", \".join([f\"({lat:.4f}, {lon:.4f})\" for lat, lon in current_locations])\n",
        "\n",
        "            # Create clean reasoning step\n",
        "            step_description = self._format_reasoning_step(response)\n",
        "            reasoning_steps.append(f\"Step {step_count+1}: {step_description} Locations: {loc_text}\")\n",
        "\n",
        "            step_count += 1\n",
        "\n",
        "            # Check if we've reached a conclusive step\n",
        "            if \"conclude\" in response.lower() or \"final\" in response.lower():\n",
        "                break\n",
        "\n",
        "        # Combine all reasoning steps\n",
        "        full_reasoning = \"\\n\".join(reasoning_steps)\n",
        "\n",
        "        return {\n",
        "            \"reasoning\": self.reasoning_template.format(reasoning_steps=full_reasoning),\n",
        "            \"locations\": current_locations,\n",
        "            \"steps\": reasoning_steps\n",
        "        }\n",
        "\n",
        "    def _prepare_step_prompt(self, query, previous_steps, current_locations, step_count):\n",
        "        \"\"\"Prepare a prompt for the next reasoning step\"\"\"\n",
        "        steps_text = \"\\n\".join(previous_steps)\n",
        "        locations_text = \", \".join([f\"({lat:.4f}, {lon:.4f})\" for lat, lon in current_locations])\n",
        "\n",
        "        if step_count == 1:\n",
        "            return f\"\"\"\n",
        "            Original query: {query}\n",
        "\n",
        "            Previous analysis:\n",
        "            {steps_text}\n",
        "\n",
        "            Current locations: {locations_text}\n",
        "\n",
        "            For Step 2, evaluate these locations by considering physical geography factors (climate, landforms)\n",
        "            that relate to the query. Provide a concise geographic insight about why these locations may or may\n",
        "            not match the query. If a different location would be more appropriate, suggest it.\n",
        "            \"\"\"\n",
        "        elif step_count == 2:\n",
        "            return f\"\"\"\n",
        "            Original query: {query}\n",
        "\n",
        "            Previous analysis:\n",
        "            {steps_text}\n",
        "\n",
        "            Current locations: {locations_text}\n",
        "\n",
        "            For Step 3, refine your analysis by considering human geography elements (cultural significance,\n",
        "            economic activities, urban patterns) that relate to the query. Be specific about why certain\n",
        "            locations are more relevant than others.\n",
        "            \"\"\"\n",
        "        else:\n",
        "            return f\"\"\"\n",
        "            Original query: {query}\n",
        "\n",
        "            Previous analysis:\n",
        "            {steps_text}\n",
        "\n",
        "            Current locations: {locations_text}\n",
        "\n",
        "            For Step {step_count+1}, conclude your analysis by identifying the most appropriate location(s)\n",
        "            that address the query, explaining the geographic reasoning behind your final selection.\n",
        "            \"\"\"\n",
        "\n",
        "    def _reasoning_system_prompt(self):\n",
        "        \"\"\"System prompt for structured geographic reasoning\"\"\"\n",
        "        return \"\"\"You are a geographic reasoning expert that provides step-by-step analysis of geographic queries.\n",
        "\n",
        "        For each step, provide concise geographic insights about locations, focusing on:\n",
        "        1. Physical geography (landforms, climate, ecosystems)\n",
        "        2. Human geography (settlements, economies, cultural patterns)\n",
        "        3. Spatial relationships between places\n",
        "\n",
        "        Your analysis should be factual and focused. Avoid unnecessary descriptions.\n",
        "        When suggesting locations, explain your geographical reasoning clearly.\n",
        "\n",
        "        Respond in a brief, direct style focused only on geographic analysis.\n",
        "        \"\"\"\n",
        "\n",
        "    def _extract_locations_from_response(self, response):\n",
        "        \"\"\"Extract location coordinates from a response using regex\"\"\"\n",
        "        import re\n",
        "\n",
        "        # Look for coordinate patterns like (42.3601, -71.0589)\n",
        "        coord_pattern = r'\\(\\s*(-?\\d+\\.\\d+)\\s*,\\s*(-?\\d+\\.\\d+)\\s*\\)'\n",
        "        matches = re.findall(coord_pattern, response)\n",
        "\n",
        "        # Convert to float tuples\n",
        "        locations = []\n",
        "        for lat_str, lon_str in matches:\n",
        "            try:\n",
        "                lat, lon = float(lat_str), float(lon_str)\n",
        "                # Basic validation of coordinates\n",
        "                if -90 <= lat <= 90 and -180 <= lon <= 180:\n",
        "                    locations.append((lat, lon))\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "        return locations\n",
        "\n",
        "    def _extract_place_names(self, response):\n",
        "        \"\"\"Extract potential place names from response\"\"\"\n",
        "        import re\n",
        "        import nltk\n",
        "\n",
        "        try:\n",
        "            nltk.data.find('tokenizers/punkt')\n",
        "        except LookupError:\n",
        "            nltk.download('punkt', quiet=True)\n",
        "\n",
        "        try:\n",
        "            nltk.data.find('taggers/averaged_perceptron_tagger')\n",
        "        except LookupError:\n",
        "            nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "\n",
        "        try:\n",
        "            nltk.data.find('chunkers/maxent_ne_chunker')\n",
        "        except LookupError:\n",
        "            nltk.download('maxent_ne_chunker', quiet=True)\n",
        "\n",
        "        try:\n",
        "            nltk.data.find('corpora/words')\n",
        "        except LookupError:\n",
        "            nltk.download('words', quiet=True)\n",
        "\n",
        "        # Extract proper nouns that might be places\n",
        "        sentences = nltk.sent_tokenize(response)\n",
        "        place_candidates = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            # Tokenize and POS tag\n",
        "            tokens = nltk.word_tokenize(sentence)\n",
        "            tagged = nltk.pos_tag(tokens)\n",
        "\n",
        "            # Extract named entities\n",
        "            entities = nltk.ne_chunk(tagged)\n",
        "\n",
        "            # Look for GPE (GeoPolitical Entity) and LOCATION entities\n",
        "            for entity in entities:\n",
        "                if hasattr(entity, 'label'):\n",
        "                    if entity.label() in ('GPE', 'LOCATION'):\n",
        "                        place_name = ' '.join([word for word, tag in entity.leaves()])\n",
        "                        place_candidates.append(place_name)\n",
        "\n",
        "        # If no entities found, use common place name patterns\n",
        "        if not place_candidates:\n",
        "            # Look for capitalized phrases that might be place names\n",
        "            cap_phrases = re.findall(r'\\b([A-Z][a-z]+(?: [A-Z][a-z]+)*)\\b', response)\n",
        "            place_candidates.extend(cap_phrases)\n",
        "\n",
        "        return list(set(place_candidates))  # Remove duplicates\n",
        "\n",
        "    def _format_reasoning_step(self, response):\n",
        "        \"\"\"Format a coherent reasoning step from the response\"\"\"\n",
        "        # Extract the main analysis, removing any preamble or closing\n",
        "        # Look for sentences with geographical content\n",
        "        import re\n",
        "        import nltk\n",
        "\n",
        "        try:\n",
        "            nltk.data.find('tokenizers/punkt')\n",
        "        except LookupError:\n",
        "            nltk.download('punkt', quiet=True)\n",
        "\n",
        "        sentences = nltk.sent_tokenize(response)\n",
        "\n",
        "        # Keywords indicating geographic reasoning\n",
        "        geo_keywords = [\n",
        "            'region', 'area', 'location', 'climate', 'terrain',\n",
        "            'landform', 'mountain', 'river', 'coast', 'urban',\n",
        "            'city', 'country', 'population', 'ecosystem', 'environment'\n",
        "        ]\n",
        "\n",
        "        # Extract sentences with geographic content\n",
        "        geo_sentences = []\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()\n",
        "            if any(keyword in sentence.lower() for keyword in geo_keywords):\n",
        "                geo_sentences.append(sentence)\n",
        "            elif re.search(r'\\b[A-Z][a-z]+\\b', sentence):  # Contains proper nouns\n",
        "                geo_sentences.append(sentence)\n",
        "\n",
        "        # If no geographic sentences found, take first 1-2 sentences\n",
        "        if not geo_sentences and sentences:\n",
        "            geo_sentences = sentences[:min(2, len(sentences))]\n",
        "\n",
        "        # Combine into coherent text (max ~50 words)\n",
        "        reasoning = ' '.join(geo_sentences)\n",
        "\n",
        "        # Truncate if too long while preserving sentence boundaries\n",
        "        if len(reasoning.split()) > 50:\n",
        "            shortened = []\n",
        "            word_count = 0\n",
        "            for sentence in nltk.sent_tokenize(reasoning):\n",
        "                sentence_words = len(sentence.split())\n",
        "                if word_count + sentence_words <= 50:\n",
        "                    shortened.append(sentence)\n",
        "                    word_count += sentence_words\n",
        "                else:\n",
        "                    break\n",
        "            reasoning = ' '.join(shortened)\n",
        "\n",
        "        return reasoning\n",
        "\n",
        "\n",
        "class GeographicKnowledgeExtractor:\n",
        "    \"\"\"\n",
        "    Extract geographic knowledge from GeoCLIP embeddings\n",
        "    \"\"\"\n",
        "    def __init__(self, geonut):\n",
        "        self.geonut = geonut\n",
        "        self.dimension_meanings = {}  # Cache for analyzed dimension meanings\n",
        "\n",
        "    def analyze_embedding_dimensions(self, sample_size=100, top_k=20):\n",
        "        \"\"\"\n",
        "        Analyze what geographic features each embedding dimension might represent\n",
        "\n",
        "        Args:\n",
        "            sample_size: Number of random locations to sample\n",
        "            top_k: Number of top dimensions to analyze\n",
        "\n",
        "        Returns:\n",
        "            Dictionary mapping dimensions to potential geographic meanings\n",
        "        \"\"\"\n",
        "        # Sample random coordinates from GeoCLIP's gallery\n",
        "        gps_gallery = self.geonut.geoclip.gps_gallery.cpu().numpy()\n",
        "        indices = np.random.choice(len(gps_gallery), min(sample_size, len(gps_gallery)), replace=False)\n",
        "        coords_list = [(float(gps_gallery[i][0]), float(gps_gallery[i][1])) for i in indices]\n",
        "\n",
        "        # Get embeddings for all locations\n",
        "        embeddings = []\n",
        "        for coords in coords_list:\n",
        "            embedding = self.geonut.encode_location(coords)\n",
        "            embeddings.append(embedding[0].cpu().numpy())\n",
        "\n",
        "        embeddings_array = np.array(embeddings)\n",
        "\n",
        "        # For each dimension, find the top locations and query what they represent\n",
        "        dimension_analysis = {}\n",
        "\n",
        "        for dim in range(min(512, top_k)):  # Analyze top_k dimensions\n",
        "            # Get locations with highest values for this dimension\n",
        "            dim_values = embeddings_array[:, dim]\n",
        "            top_indices = np.argsort(dim_values)[-5:]  # Top 5 locations\n",
        "\n",
        "            top_locations = [coords_list[i] for i in top_indices]\n",
        "\n",
        "            # Create prompt to analyze what these locations have in common\n",
        "            prompt = f\"\"\"Analyze these geographic coordinates and explain what common geographic features they might share:\n",
        "\n",
        "            {top_locations}\n",
        "\n",
        "            Focus on physical geography (landforms, climate, water bodies) and human geography (urbanization, land use).\n",
        "            What geographic pattern might dimension {dim} in a location embedding represent?\n",
        "\n",
        "            Be specific but concise (3-5 sentences maximum).\n",
        "            \"\"\"\n",
        "\n",
        "            # Get analysis from LLM\n",
        "            messages = [\n",
        "                {\"role\": \"system\", \"content\": \"You are a geographic analyst specializing in identifying patterns from coordinates.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "\n",
        "            response = self.geonut.generate_response(\n",
        "                messages=messages,\n",
        "                coords_list=top_locations,\n",
        "                max_new_tokens=200\n",
        "            )\n",
        "\n",
        "            # Store analysis\n",
        "            dimension_analysis[dim] = {\n",
        "                \"description\": response,\n",
        "                \"top_locations\": top_locations,\n",
        "                \"value_range\": (float(np.min(dim_values)), float(np.max(dim_values)))\n",
        "            }\n",
        "\n",
        "        self.dimension_meanings = dimension_analysis\n",
        "        return dimension_analysis\n",
        "\n",
        "    def extract_regional_knowledge(self, region_name, radius=100):\n",
        "        \"\"\"\n",
        "        Extract geographic knowledge about a specific region\n",
        "\n",
        "        Args:\n",
        "            region_name: Name of the region to analyze\n",
        "            radius: Radius in km to sample around the region center\n",
        "\n",
        "        Returns:\n",
        "            Dictionary with geographic analysis of the region\n",
        "        \"\"\"\n",
        "        # Find coordinates for the region\n",
        "        locations = self.geonut.get_nearest_locations(region_name, top_k=1)\n",
        "        if not locations:\n",
        "            return {\"error\": f\"Could not find coordinates for {region_name}\"}\n",
        "\n",
        "        center_coords = locations[0][0]\n",
        "\n",
        "        # Sample points around the center\n",
        "        import geopy.distance\n",
        "\n",
        "        coords_list = [center_coords]\n",
        "\n",
        "        # Sample in 8 directions\n",
        "        directions = [0, 45, 90, 135, 180, 225, 270, 315]\n",
        "        for direction in directions:\n",
        "            dest = geopy.distance.distance(kilometers=radius).destination(\n",
        "                point=center_coords, bearing=direction)\n",
        "            coords_list.append((dest.latitude, dest.longitude))\n",
        "\n",
        "        # Get embeddings for all points\n",
        "        embeddings = []\n",
        "        for coords in coords_list:\n",
        "            embedding = self.geonut.encode_location(coords)\n",
        "            embeddings.append(embedding[0].cpu().numpy())\n",
        "\n",
        "        center_embedding = embeddings[0]\n",
        "        region_embeddings = np.array(embeddings[1:])\n",
        "\n",
        "        # Find salient dimensions (those with highest variance or highest values)\n",
        "        dim_values = np.abs(center_embedding)\n",
        "        top_dims = np.argsort(dim_values)[-10:]  # Top 10 dimensions\n",
        "\n",
        "        # Create prompt for geographic analysis\n",
        "        dim_text = \", \".join([f\"Dimension {dim}\" for dim in top_dims])\n",
        "\n",
        "        prompt = f\"\"\"Analyze the geographic characteristics of {region_name} (coordinates: {center_coords}).\n",
        "\n",
        "The region has significant values in these embedding dimensions: {dim_text}.\n",
        "\n",
        "Provide a comprehensive geographic analysis of this region, covering:\n",
        "1. Physical geography (landforms, climate, water bodies, ecosystems)\n",
        "2. Human geography (settlement patterns, economic activities, cultural landscape)\n",
        "3. Distinctive geographic features that make this region unique\n",
        "\n",
        "Your analysis should be factual and detailed, drawing on geographic knowledge.\n",
        "\"\"\"\n",
        "\n",
        "        # Get analysis from LLM\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a geographic analyst specializing in regional geography.\"},\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ]\n",
        "\n",
        "        response = self.geonut.generate_response(\n",
        "            messages=messages,\n",
        "            coords_list=[center_coords],\n",
        "            max_new_tokens=500\n",
        "        )\n",
        "\n",
        "        # Structure the results\n",
        "        result = {\n",
        "            \"region_name\": region_name,\n",
        "            \"coordinates\": center_coords,\n",
        "            \"salient_dimensions\": top_dims.tolist(),\n",
        "            \"analysis\": response,\n",
        "            \"embedding_stats\": {\n",
        "                \"mean\": float(np.mean(center_embedding)),\n",
        "                \"std\": float(np.std(center_embedding)),\n",
        "                \"min\": float(np.min(center_embedding)),\n",
        "                \"max\": float(np.max(center_embedding))\n",
        "            }\n",
        "        }\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "def resolve_location_query(geonut, query, use_structured_reasoning=True):\n",
        "    \"\"\"\n",
        "    Enhanced function to resolve geographic queries with structured reasoning\n",
        "\n",
        "    Args:\n",
        "        geonut: GeoNut instance\n",
        "        query: Geographic query text\n",
        "        use_structured_reasoning: Whether to use structured reasoning or simple lookup\n",
        "\n",
        "    Returns:\n",
        "        Dict with reasoning process and resulting locations\n",
        "    \"\"\"\n",
        "    if use_structured_reasoning:\n",
        "        # Use structured geographic reasoning\n",
        "        reasoner = GeoReasoner(geonut)\n",
        "        result = reasoner.structured_geographic_analysis(query)\n",
        "        return result\n",
        "    else:\n",
        "        # Simple location lookup\n",
        "        locations = geonut.get_nearest_locations(query, top_k=5)\n",
        "\n",
        "        # Generate brief explanation\n",
        "        location_text = \", \".join([f\"({lat:.4f}, {lon:.4f})\" for (lat, lon), _ in locations[:3]])\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": \"You are a geographic expert. Explain why these locations match the query.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Query: {query}\\nTop matching locations: {location_text}\\n\\nExplain why these locations match the query.\"}\n",
        "        ]\n",
        "\n",
        "        explanation = geonut.generate_response(\n",
        "            messages=messages,\n",
        "            coords_list=[coords for coords, _ in locations[:3]],\n",
        "            max_new_tokens=200\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"locations\": [coords for coords, _ in locations],\n",
        "            \"confidence_scores\": [float(score) for _, score in locations],\n",
        "            \"explanation\": explanation\n",
        "        }"
      ],
      "metadata": {
        "id": "f0E8zQvG1mrs"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from geonut import GeoNut\n",
        "geonut = GeoNut(llm_model_id=\"your-model\")\n",
        "result = resolve_location_query(geonut, \"Find a vibrant coastal city with Mardi Gras celebrations\")\n",
        "print(result[\"reasoning\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "-GWwIXY81oR-",
        "outputId": "a2c7e626-b2c4-42d0-ab10-795156ea9e92"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'GeoNut' from 'geonut' (/content/geonut.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-71f253d5a422>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgeonut\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeoNut\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgeonut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeoNut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_model_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"your-model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolve_location_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeonut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Find a vibrant coastal city with Mardi Gras celebrations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reasoning\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GeoNut' from 'geonut' (/content/geonut.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "source": [
        "import os\n",
        "\n",
        "# Create the package directory if it doesn't exist\n",
        "if not os.path.exists(\"geonut_package\"):\n",
        "    os.makedirs(\"geonut_package\")\n",
        "\n",
        "# Move geonut.py to the package directory\n",
        "!mv geonut.py geonut_package/\n",
        "\n",
        "# Create an empty __init__.py file\n",
        "with open(\"geonut_package/__init__.py\", \"w\") as f:\n",
        "    pass"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "nmNlmTtD12Zv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "source": [
        "from geonut_package.geonut import GeoNut  # Updated import statement\n",
        "geonut = GeoNut(llm_model_id=\"your-model\")\n",
        "result = resolve_location_query(geonut, \"Find a vibrant coastal city with Mardi Gras celebrations\")\n",
        "print(result[\"reasoning\"])"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "sYcSbJfy13nx",
        "outputId": "943cf3e7-4195-41ff-ebd2-187d4d572d21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'GeoNut' from 'geonut_package.geonut' (/content/geonut_package/geonut.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-324d0bd666e7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgeonut_package\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeonut\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGeoNut\u001b[0m  \u001b[0;31m# Updated import statement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgeonut\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeoNut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_model_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"your-model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresolve_location_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeonut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Find a vibrant coastal city with Mardi Gras celebrations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"reasoning\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'GeoNut' from 'geonut_package.geonut' (/content/geonut_package/geonut.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMuVrWbjAzhc"
      },
      "source": [
        "<a name=\"Save\"></a>\n",
        "### Saving, loading finetuned models\n",
        "To save the final model as LoRA adapters, either use Huggingface's `push_to_hub` for an online save or `save_pretrained` for a local save.\n",
        "\n",
        "**[NOTE]** This ONLY saves the LoRA adapters, and not the full model. To save to 16bit or GGUF, scroll down!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcOlWe7A1vc",
        "outputId": "c962e43a-2027-4a39-ea03-870b707a22d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('lora_model/tokenizer_config.json',\n",
              " 'lora_model/special_tokens_map.json',\n",
              " 'lora_model/tokenizer.json')"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained(\"lora_model\")  # Local saving\n",
        "tokenizer.save_pretrained(\"lora_model\")\n",
        "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
        "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEEcJ4qfC7Lp"
      },
      "source": [
        "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MKX_XKs_BNZR",
        "outputId": "f22dbd75-ea37-48bb-9f75-4178aebe9353"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Eiffel Tower, located in the heart of Paris, stands tall among the city's historic and cultural landmarks. This iron structure, standing at an impressive 324 meters high, offers breathtaking views of the City of Light's iconic landscape. The Eiffel Tower was built for the 1889 World's Fair and has since become a symbol of French engineering and culture.<|eot_id|>\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "    from unsloth import FastLanguageModel\n",
        "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "        model_name = \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        max_seq_length = max_seq_length,\n",
        "        dtype = dtype,\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Describe a tall tower in the capital of France.\"},\n",
        "]\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
        "_ = model.generate(input_ids = inputs, streamer = text_streamer, max_new_tokens = 128,\n",
        "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMjaNrjsU5_"
      },
      "source": [
        "You can also use Hugging Face's `AutoModelForPeftCausalLM`. Only use this if you do not have `unsloth` installed. It can be hopelessly slow, since `4bit` model downloading is not supported, and Unsloth's **inference is 2x faster**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yFfaXG0WsQuE"
      },
      "outputs": [],
      "source": [
        "if False:\n",
        "    # I highly do NOT suggest - use Unsloth if possible\n",
        "    from peft import AutoPeftModelForCausalLM\n",
        "    from transformers import AutoTokenizer\n",
        "    model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "        \"lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
        "        load_in_4bit = load_in_4bit,\n",
        "    )\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"lora_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF.\n",
        "\n",
        "Some supported quant methods (full list on our [Wiki page](https://github.com/unslothai/unsloth/wiki#gguf-quantization-options)):\n",
        "* `q8_0` - Fast conversion. High resource use, but generally acceptable.\n",
        "* `q4_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q4_K.\n",
        "* `q5_k_m` - Recommended. Uses Q6_K for half of the attention.wv and feed_forward.w2 tensors, else Q5_K.\n",
        "\n",
        "[**NEW**] To finetune and auto export to Ollama, try our [Ollama notebook](https://colab.research.google.com/drive/1WZDi7APtQ9VsvOrQSSC5DDtxq159j8iZ?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "# Remember to go to https://huggingface.co/settings/tokens for a token!\n",
        "# And change hf to your username!\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")\n",
        "\n",
        "# Save to multiple GGUF options - much faster if you want multiple!\n",
        "if False:\n",
        "    model.push_to_hub_gguf(\n",
        "        \"hf/model\", # Change hf to your username!\n",
        "        tokenizer,\n",
        "        quantization_method = [\"q4_k_m\", \"q8_0\", \"q5_k_m\",],\n",
        "        token = \"\", # Get a token at https://huggingface.co/settings/tokens\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwwuZ7V2us-T"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in llama.cpp or a UI based system like Jan or Open WebUI. You can install Jan [here](https://github.com/janhq/jan) and Open WebUI [here](https://github.com/open-webui/open-webui)\n",
        "\n",
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/unsloth) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Train your own reasoning model - Llama GRPO notebook [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb)\n",
        "2. Saving finetunes to Ollama. [Free notebook](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3_(8B)-Ollama.ipynb)\n",
        "3. Llama 3.2 Vision finetuning - Radiography use case. [Free Colab](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.2_(11B)-Vision.ipynb)\n",
        "6. See notebooks for DPO, ORPO, Continued pretraining, conversational finetuning and more on our [documentation](https://docs.unsloth.ai/get-started/unsloth-notebooks)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://unsloth.ai\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://docs.unsloth.ai/\"><img src=\"https://github.com/unslothai/unsloth/blob/main/images/documentation%20green%20button.png?raw=true\" width=\"125\"></a>\n",
        "\n",
        "  Join Discord if you need help + ‚≠êÔ∏è <i>Star us on <a href=\"https://github.com/unslothai/unsloth\">Github</a> </i> ‚≠êÔ∏è\n",
        "</div>\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "007a35a241b346ec9a5cdd6f3e4ddd27": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4083b2ef8e6348e18b69d116508b46ff",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9555be409a2c4a97b18d4978ed13d35f",
            "value": "README.md:‚Äá100%"
          }
        },
        "0bfbfe620ff446a0a47f7d5de7c88975": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c30ded692064dc7bf36a93897f2b68f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e4ea03959b3496f8e75cc3588cf347c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a6ca29a76ff430d86213f910858db5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95249b8fb6a84054a01f22c5f73f207b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2ed2b017b9a24f36a4222c5c27753991",
            "value": "‚Äá100000/100000‚Äá[00:01&lt;00:00,‚Äá63603.83‚Äáexamples/s]"
          }
        },
        "2b359412d4914aa38a6e21284c12ecbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddee625828cb4c22927aa73a02cd2dd9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_fd46f381983f49179de05497c171c805",
            "value": "‚Äá117M/117M‚Äá[00:00&lt;00:00,‚Äá210MB/s]"
          }
        },
        "2bb75539976c49ed805c4ff6c58fb1d2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ed2b017b9a24f36a4222c5c27753991": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "39684b70f2ff48cab454617c721f7777": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8445e90b1054aacbecf198c7979a0b6",
              "IPY_MODEL_d1cc50fb6d5849888af5d765dc51ab62",
              "IPY_MODEL_2b359412d4914aa38a6e21284c12ecbc"
            ],
            "layout": "IPY_MODEL_a4ceb6dbc8de4fa798ee39d28e5ebc40"
          }
        },
        "39bf1c29894f43acb6d2919e64a4fd28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_007a35a241b346ec9a5cdd6f3e4ddd27",
              "IPY_MODEL_969a119573f942b29951ae2933e61cde",
              "IPY_MODEL_b8c4d378ea0e4bcd9f572a191a7c136f"
            ],
            "layout": "IPY_MODEL_7d37dd0e06724b53b4f31cc0a4321b0d"
          }
        },
        "4083b2ef8e6348e18b69d116508b46ff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45bc9d882a8f4a7e813245b1590d4427": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5628ed38f304438faf5442b29a9511d6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9ee920068a47d89dbf5cbdd9e848a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e9825466cd2481b92cfe89f33b11fe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c685f29a5d2c461ca3dda867bab6df50",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e2f16d56b21c4ff2918872d70e5ca847",
            "value": "Generating‚Äátrain‚Äásplit:‚Äá100%"
          }
        },
        "6064feeea79040409e18a1e2a289b09a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bb241a26ca4d4d7186ba46cda1f8a802",
              "IPY_MODEL_c9abb42da1734388a7d2f1a06832ecc6",
              "IPY_MODEL_7c3a37494e5848b9994b37a4c8bac132"
            ],
            "layout": "IPY_MODEL_c668ae4c7d174f2dad3fb837ff873e57"
          }
        },
        "6d52daf29c90402a9762acdde765713f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6e0fe945001140b3959e617a2f55c353": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "785d9147f4a341afafc5c5743892df16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e9825466cd2481b92cfe89f33b11fe3",
              "IPY_MODEL_bfbb37b6f4b247b5bf5aaf7e1d80bcf9",
              "IPY_MODEL_2a6ca29a76ff430d86213f910858db5b"
            ],
            "layout": "IPY_MODEL_92d981a21b204f6c8b52e3caa16d1784"
          }
        },
        "7c3a37494e5848b9994b37a4c8bac132": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5cfa138483f4007b2a95be833043235",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_6d52daf29c90402a9762acdde765713f",
            "value": "‚Äá100000/100000‚Äá[01:07&lt;00:00,‚Äá2101.01‚Äáexamples/s]"
          }
        },
        "7d37dd0e06724b53b4f31cc0a4321b0d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "870ff8f17c7b47ec8d49cac84216b04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c5ad85b4da14b239340ac95244d8ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "904e7bac43bd4333b321cacfed5dcb60": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "92d981a21b204f6c8b52e3caa16d1784": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95249b8fb6a84054a01f22c5f73f207b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9555be409a2c4a97b18d4978ed13d35f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "969a119573f942b29951ae2933e61cde": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5628ed38f304438faf5442b29a9511d6",
            "max": 982,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e0fe945001140b3959e617a2f55c353",
            "value": 982
          }
        },
        "a4ceb6dbc8de4fa798ee39d28e5ebc40": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8c4d378ea0e4bcd9f572a191a7c136f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c30ded692064dc7bf36a93897f2b68f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_8c5ad85b4da14b239340ac95244d8ed4",
            "value": "‚Äá982/982‚Äá[00:00&lt;00:00,‚Äá21.3kB/s]"
          }
        },
        "bb241a26ca4d4d7186ba46cda1f8a802": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd30f3ead6394317be5a72aa890adfb9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_1e4ea03959b3496f8e75cc3588cf347c",
            "value": "Map:‚Äá100%"
          }
        },
        "bfbb37b6f4b247b5bf5aaf7e1d80bcf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0bfbfe620ff446a0a47f7d5de7c88975",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c9ee920068a47d89dbf5cbdd9e848a3",
            "value": 100000
          }
        },
        "c668ae4c7d174f2dad3fb837ff873e57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c685f29a5d2c461ca3dda867bab6df50": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9abb42da1734388a7d2f1a06832ecc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d356b597dda14c7ab023403ee6959cf8",
            "max": 100000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_870ff8f17c7b47ec8d49cac84216b04c",
            "value": 100000
          }
        },
        "d1cc50fb6d5849888af5d765dc51ab62": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bb75539976c49ed805c4ff6c58fb1d2",
            "max": 116531415,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45bc9d882a8f4a7e813245b1590d4427",
            "value": 116531404
          }
        },
        "d356b597dda14c7ab023403ee6959cf8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5cfa138483f4007b2a95be833043235": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6ab4d4143ff49bcae30be1bc2d76762": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd30f3ead6394317be5a72aa890adfb9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddee625828cb4c22927aa73a02cd2dd9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f16d56b21c4ff2918872d70e5ca847": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8445e90b1054aacbecf198c7979a0b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ab4d4143ff49bcae30be1bc2d76762",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_904e7bac43bd4333b321cacfed5dcb60",
            "value": "train-00000-of-00001.parquet:‚Äá100%"
          }
        },
        "fd46f381983f49179de05497c171c805": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3bebecbd48d4522bab6611255a64f9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf0c470d44cd45a5a1dd523b2b17d8f3",
              "IPY_MODEL_9ffea1ec2a1e4f3fb6d93e7fca53606f",
              "IPY_MODEL_af2944cd893d4acaa9bf8ada72d6c040"
            ],
            "layout": "IPY_MODEL_49c962fd2fc2490ea07bdbd9850022d8"
          }
        },
        "bf0c470d44cd45a5a1dd523b2b17d8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81c0551ea8fa4a9c91130b436916d769",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_147640b2354e4f0aa11c0b203e32dea5",
            "value": "model.safetensors:‚Äá100%"
          }
        },
        "9ffea1ec2a1e4f3fb6d93e7fca53606f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb3b8e761fd1414db331bc12ffc704f6",
            "max": 2242762780,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d8ca9ea138f340e6b738f440ac05e6da",
            "value": 2242762567
          }
        },
        "af2944cd893d4acaa9bf8ada72d6c040": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1d254c3c25841f79d67903dfa039415",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ab6ffa70c77d402f84cf58be80b4a328",
            "value": "‚Äá2.24G/2.24G‚Äá[00:21&lt;00:00,‚Äá616MB/s]"
          }
        },
        "49c962fd2fc2490ea07bdbd9850022d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81c0551ea8fa4a9c91130b436916d769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "147640b2354e4f0aa11c0b203e32dea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb3b8e761fd1414db331bc12ffc704f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8ca9ea138f340e6b738f440ac05e6da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1d254c3c25841f79d67903dfa039415": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab6ffa70c77d402f84cf58be80b4a328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a23b252875e242da8b7ecabaf8e08bc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13cfc66228c44bd68d6cc77ff4697a58",
              "IPY_MODEL_5f604b90d395441e862616df04da2cd8",
              "IPY_MODEL_7489fb2e9be248878b6195033b637e2c"
            ],
            "layout": "IPY_MODEL_d0db9b51e9af45dc9b1da6a01dfb081a"
          }
        },
        "13cfc66228c44bd68d6cc77ff4697a58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1fe8a317af924c388abda2e543bff090",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_12cdc1f761dd481ab530275bd0744746",
            "value": "generation_config.json:‚Äá100%"
          }
        },
        "5f604b90d395441e862616df04da2cd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5f53a72eb6f4f4e90bfa9425c59c66c",
            "max": 234,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3958675895a747ea9b340e0ebf8a0a31",
            "value": 234
          }
        },
        "7489fb2e9be248878b6195033b637e2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79d4c701d3c544198d280a8f2acbf22a",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e4ff4b412d5b47a580b65a308f3e7952",
            "value": "‚Äá234/234‚Äá[00:00&lt;00:00,‚Äá23.9kB/s]"
          }
        },
        "d0db9b51e9af45dc9b1da6a01dfb081a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1fe8a317af924c388abda2e543bff090": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12cdc1f761dd481ab530275bd0744746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b5f53a72eb6f4f4e90bfa9425c59c66c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3958675895a747ea9b340e0ebf8a0a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "79d4c701d3c544198d280a8f2acbf22a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4ff4b412d5b47a580b65a308f3e7952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44c2a8346d0149f0ae67975557b65ced": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_496e73a1e1794280bdfdd0ebea474744",
              "IPY_MODEL_f3ddbffb0869478298fbc8de810a7cf8",
              "IPY_MODEL_6443d11b2d5a4215b61c3478b3845741"
            ],
            "layout": "IPY_MODEL_9d65638fc98f4f9fb683dad3ffe072e4"
          }
        },
        "496e73a1e1794280bdfdd0ebea474744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fa9aeb577c048ae822dc22718429941",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_480767b02c3b4bc0bb155f01f7cc66a0",
            "value": "tokenizer_config.json:‚Äá100%"
          }
        },
        "f3ddbffb0869478298fbc8de810a7cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_384276b53c64497598411b6109a377d9",
            "max": 54674,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61f576ebd82e4e0d832875e6230bfca9",
            "value": 54674
          }
        },
        "6443d11b2d5a4215b61c3478b3845741": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4659321d09624f838638199ee8ccd7eb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_3cd700d9a4c64b55bdf8a5c2bfbe02f1",
            "value": "‚Äá54.7k/54.7k‚Äá[00:00&lt;00:00,‚Äá5.70MB/s]"
          }
        },
        "9d65638fc98f4f9fb683dad3ffe072e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fa9aeb577c048ae822dc22718429941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "480767b02c3b4bc0bb155f01f7cc66a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "384276b53c64497598411b6109a377d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f576ebd82e4e0d832875e6230bfca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4659321d09624f838638199ee8ccd7eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3cd700d9a4c64b55bdf8a5c2bfbe02f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "27975910e7ce4a85a6cefd49e33f9f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbcdaa17ac524be087d174a409d74959",
              "IPY_MODEL_42cf68b7b302416d99cc27205ba1d7d8",
              "IPY_MODEL_58b2976f940e443e83e63bec2252b307"
            ],
            "layout": "IPY_MODEL_31d24404dde8446a99f6b7b81cd4d645"
          }
        },
        "cbcdaa17ac524be087d174a409d74959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1647f67e661641ac87fdce43d6f9cc13",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c7c1c9698e0143c5b7234b995468706a",
            "value": "tokenizer.json:‚Äá100%"
          }
        },
        "42cf68b7b302416d99cc27205ba1d7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb4a4564bbe94f00a1c7d11e92d230a1",
            "max": 17209920,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91ee4508c6fb420b8198f605e542451c",
            "value": 17209920
          }
        },
        "58b2976f940e443e83e63bec2252b307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a74eb446e5584c8da2233eee1f764cfb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_422c4e61c09f4be3a89499a317705682",
            "value": "‚Äá17.2M/17.2M‚Äá[00:00&lt;00:00,‚Äá146MB/s]"
          }
        },
        "31d24404dde8446a99f6b7b81cd4d645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1647f67e661641ac87fdce43d6f9cc13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7c1c9698e0143c5b7234b995468706a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bb4a4564bbe94f00a1c7d11e92d230a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91ee4508c6fb420b8198f605e542451c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a74eb446e5584c8da2233eee1f764cfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "422c4e61c09f4be3a89499a317705682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "341b0b0c997a49fba6dcaa463e98d3f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46716ccec92f4f53bf8e8a974981988f",
              "IPY_MODEL_10ac78a28fe64ae09a6ea68d657c60d6",
              "IPY_MODEL_30087cfc889e4728831f492362be5c58"
            ],
            "layout": "IPY_MODEL_c2c4ab61d42f46d5a7c009e4759a6101"
          }
        },
        "46716ccec92f4f53bf8e8a974981988f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0451be40600f404d9dc76f0db770e1cb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_65b5b3a46c614a0f9a7d0a1ca24a6e79",
            "value": "special_tokens_map.json:‚Äá100%"
          }
        },
        "10ac78a28fe64ae09a6ea68d657c60d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc11742a8b314f7f9b6df4dd430e9b3e",
            "max": 454,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ce3df098ca8247b496afac1b6ffaed14",
            "value": 454
          }
        },
        "30087cfc889e4728831f492362be5c58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c042b35292ad4046b3e2fd3a0c4b0379",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_60e70b6be38a4cfea47f519a8c079036",
            "value": "‚Äá454/454‚Äá[00:00&lt;00:00,‚Äá36.5kB/s]"
          }
        },
        "c2c4ab61d42f46d5a7c009e4759a6101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0451be40600f404d9dc76f0db770e1cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65b5b3a46c614a0f9a7d0a1ca24a6e79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc11742a8b314f7f9b6df4dd430e9b3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce3df098ca8247b496afac1b6ffaed14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c042b35292ad4046b3e2fd3a0c4b0379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60e70b6be38a4cfea47f519a8c079036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca0bca9eda354fb7ab562c35fe54b473": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05e456d6dc7a4fb7b758a48df122c1b6",
              "IPY_MODEL_e337088d0bb44c83a22b39f34b80e5d3",
              "IPY_MODEL_00ed61c29edc478194e71b55bd4cd077"
            ],
            "layout": "IPY_MODEL_7154c3aa2e524d4a9ed615546b419937"
          }
        },
        "05e456d6dc7a4fb7b758a48df122c1b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a695addc5354c33b5678304dd8549f1",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_e6b1aac504c84b3caeec68d0231805e3",
            "value": "Map:‚Äá100%"
          }
        },
        "e337088d0bb44c83a22b39f34b80e5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_271c4384fd524cea94ee6cb4fb74a60d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b121d938983459d9282273d14517b6d",
            "value": 2
          }
        },
        "00ed61c29edc478194e71b55bd4cd077": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4515f11c1498428bacf5d142e6311f11",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_a30b2456a6fa41439b369f5434b909ef",
            "value": "‚Äá2/2‚Äá[00:00&lt;00:00,‚Äá49.93‚Äáexamples/s]"
          }
        },
        "7154c3aa2e524d4a9ed615546b419937": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a695addc5354c33b5678304dd8549f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6b1aac504c84b3caeec68d0231805e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "271c4384fd524cea94ee6cb4fb74a60d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b121d938983459d9282273d14517b6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4515f11c1498428bacf5d142e6311f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a30b2456a6fa41439b369f5434b909ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6b54416c3b545db947ed0b9fa4baa0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73c0bc0d709b413e904d6857769dfc96",
              "IPY_MODEL_d51479062aa14825bc20e0cfe6ed60f9",
              "IPY_MODEL_3d3e3ad20dae43a8a37efcad87c59895"
            ],
            "layout": "IPY_MODEL_46a267a5cec94d51b41adda948f951f7"
          }
        },
        "73c0bc0d709b413e904d6857769dfc96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19a3803841b44d0dacd0428e306fbb6c",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_dc1a22a639174a8cbc67cfd89e516415",
            "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "d51479062aa14825bc20e0cfe6ed60f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdd4a493ad744db09065916ab8fb4f1d",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_54f5a7d03af744a587f8d0dbb11c656c",
            "value": 2
          }
        },
        "3d3e3ad20dae43a8a37efcad87c59895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1120851b9cb143218b2804121a76ef93",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ffa71351783b422092a617d228ad37b3",
            "value": "‚Äá2/2‚Äá[00:02&lt;00:00,‚Äá‚Äá2.69s/‚Äáexamples]"
          }
        },
        "46a267a5cec94d51b41adda948f951f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19a3803841b44d0dacd0428e306fbb6c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc1a22a639174a8cbc67cfd89e516415": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdd4a493ad744db09065916ab8fb4f1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54f5a7d03af744a587f8d0dbb11c656c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1120851b9cb143218b2804121a76ef93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa71351783b422092a617d228ad37b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48207920e8cc49108ef55db3c5696c22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_260abbf8ac3c4fdca89250f1234c1244",
              "IPY_MODEL_acc6c94d30374d839d1174e58999f493",
              "IPY_MODEL_c8736d64f08f43ae922b363bf6ec48ac"
            ],
            "layout": "IPY_MODEL_c923cb9967094b5eb73d19e250540ec0"
          }
        },
        "260abbf8ac3c4fdca89250f1234c1244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_219d4b2f08794c238684228d4b37d1f9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c69e11a019c2409783b13295b7fcba68",
            "value": "Map‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "acc6c94d30374d839d1174e58999f493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0939b902c29a4a149b9f422ea78bf46a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dbff3be816774f7b86031fb6e22d93c7",
            "value": 2
          }
        },
        "c8736d64f08f43ae922b363bf6ec48ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_313777fe2c1b465c9bf71e410a77492b",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_2a1a4f2ed5044499b68e8614ce578100",
            "value": "‚Äá2/2‚Äá[00:00&lt;00:00,‚Äá‚Äá5.44‚Äáexamples/s]"
          }
        },
        "c923cb9967094b5eb73d19e250540ec0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "219d4b2f08794c238684228d4b37d1f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c69e11a019c2409783b13295b7fcba68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0939b902c29a4a149b9f422ea78bf46a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbff3be816774f7b86031fb6e22d93c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "313777fe2c1b465c9bf71e410a77492b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a1a4f2ed5044499b68e8614ce578100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1e49bfdf85b43e7a42a65712bb876cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7837a0671e8546b2a8ace84dcb5ae2af",
              "IPY_MODEL_bec95b1e7a4b47e4a67bb2932352a8a0",
              "IPY_MODEL_276570531ad446a7b5de3539e8b87625"
            ],
            "layout": "IPY_MODEL_abb7ddc7afba4ffea30e93f87ba8e2a4"
          }
        },
        "7837a0671e8546b2a8ace84dcb5ae2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5155429e2944e76950680b290468e12",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0480cb2de44d4b21b342843d76010c37",
            "value": "Unsloth:‚ÄáTokenizing‚Äá[&quot;text&quot;]‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "bec95b1e7a4b47e4a67bb2932352a8a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e1b1400f90d45bfaec92c8f95fc4dd3",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d814c5aec07c4f1591196168717818e0",
            "value": 2
          }
        },
        "276570531ad446a7b5de3539e8b87625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_011ecf7a5d25466cb816accbd585d08d",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0956044f839046c6a69202f909cfac6d",
            "value": "‚Äá2/2‚Äá[00:02&lt;00:00,‚Äá‚Äá1.04s/‚Äáexamples]"
          }
        },
        "abb7ddc7afba4ffea30e93f87ba8e2a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5155429e2944e76950680b290468e12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0480cb2de44d4b21b342843d76010c37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e1b1400f90d45bfaec92c8f95fc4dd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d814c5aec07c4f1591196168717818e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "011ecf7a5d25466cb816accbd585d08d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0956044f839046c6a69202f909cfac6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddcff4e758154ab891899c687b455c7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8cb5fc1745549fead153bdac67d4140",
              "IPY_MODEL_ccfecaa184fa453790a20478fece886a",
              "IPY_MODEL_12e7e7b8c35d493791916008731c64b3"
            ],
            "layout": "IPY_MODEL_2fcea7f999744e9fb1aae8fc5da1d020"
          }
        },
        "b8cb5fc1745549fead153bdac67d4140": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e23ebe2499024759a5dab02bc81cf18f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_26fb0ec96df44a28931ee181720f5e21",
            "value": "Map‚Äá(num_proc=2):‚Äá100%"
          }
        },
        "ccfecaa184fa453790a20478fece886a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f45e7900bad4d36b1ed812d61731d4f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_494fd190eac14dc4a48de1b5e3148dd3",
            "value": 2
          }
        },
        "12e7e7b8c35d493791916008731c64b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b16dfcef3bb64d2fa16c6f1b0ee6a0bf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_f792a4bf33754f3cb6cf6f43276a7924",
            "value": "‚Äá2/2‚Äá[00:00&lt;00:00,‚Äá‚Äá8.13‚Äáexamples/s]"
          }
        },
        "2fcea7f999744e9fb1aae8fc5da1d020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e23ebe2499024759a5dab02bc81cf18f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26fb0ec96df44a28931ee181720f5e21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f45e7900bad4d36b1ed812d61731d4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "494fd190eac14dc4a48de1b5e3148dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b16dfcef3bb64d2fa16c6f1b0ee6a0bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f792a4bf33754f3cb6cf6f43276a7924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}